{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>length_title</th>\n",
       "      <th>view count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tnTPaLOaHz8</td>\n",
       "      <td>$10,000 Every Day You Survive In A Grocery Store</td>\n",
       "      <td>9</td>\n",
       "      <td>217933713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wdjh81uH6FU</td>\n",
       "      <td>$1 vs $10,000,000 Job!</td>\n",
       "      <td>4</td>\n",
       "      <td>155681496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7dYTw-jAYkY</td>\n",
       "      <td>I Spent 7 Days Buried Alive</td>\n",
       "      <td>6</td>\n",
       "      <td>153336529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mwKJfNYwvm8</td>\n",
       "      <td>I Built 100 Wells In Africa</td>\n",
       "      <td>6</td>\n",
       "      <td>165967222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QjvpjXdgugA</td>\n",
       "      <td>World’s Deadliest Laser Maze!</td>\n",
       "      <td>4</td>\n",
       "      <td>169840468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>JinpVA6p8Mo</td>\n",
       "      <td>Snowball Machine Gun- How to make</td>\n",
       "      <td>6</td>\n",
       "      <td>21369170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>FRlbNOno5VA</td>\n",
       "      <td>BEST Guess Who Strategy- 96% WIN record using ...</td>\n",
       "      <td>9</td>\n",
       "      <td>28131975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>nsnyl8llfH4</td>\n",
       "      <td>1st place Egg Drop project ideas- using SCIENCE</td>\n",
       "      <td>8</td>\n",
       "      <td>37534623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>8Vc-69M-UWk</td>\n",
       "      <td>iPhone ATM PIN code hack- HOW TO PREVENT</td>\n",
       "      <td>8</td>\n",
       "      <td>38813844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-RjJtO51ykY</td>\n",
       "      <td>EASY Pinewood Derby Car WINS using Science!!!</td>\n",
       "      <td>7</td>\n",
       "      <td>30351978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "0    tnTPaLOaHz8   $10,000 Every Day You Survive In A Grocery Store   \n",
       "1    Wdjh81uH6FU                             $1 vs $10,000,000 Job!   \n",
       "2    7dYTw-jAYkY                        I Spent 7 Days Buried Alive   \n",
       "3    mwKJfNYwvm8                        I Built 100 Wells In Africa   \n",
       "4    QjvpjXdgugA                      World’s Deadliest Laser Maze!   \n",
       "..           ...                                                ...   \n",
       "332  JinpVA6p8Mo                  Snowball Machine Gun- How to make   \n",
       "333  FRlbNOno5VA  BEST Guess Who Strategy- 96% WIN record using ...   \n",
       "334  nsnyl8llfH4    1st place Egg Drop project ideas- using SCIENCE   \n",
       "335  8Vc-69M-UWk           iPhone ATM PIN code hack- HOW TO PREVENT   \n",
       "336  -RjJtO51ykY      EASY Pinewood Derby Car WINS using Science!!!   \n",
       "\n",
       "     length_title  view count  \n",
       "0               9   217933713  \n",
       "1               4   155681496  \n",
       "2               6   153336529  \n",
       "3               6   165967222  \n",
       "4               4   169840468  \n",
       "..            ...         ...  \n",
       "332             6    21369170  \n",
       "333             9    28131975  \n",
       "334             8    37534623  \n",
       "335             8    38813844  \n",
       "336             7    30351978  \n",
       "\n",
       "[337 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('data/raw_data.csv')\n",
    "length_title_view_count = pd.read_csv('data/length_title_view_count.csv')  \n",
    "length_title_view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open('frame_features.json')\n",
    "frames_features = json.load(f)\n",
    "frames_features.items()\n",
    "# length_title_view_count = length_title_view_count[frames_features.keys()]\n",
    "# length_title_view_count\n",
    "\n",
    "lst = []\n",
    "for key, val in frames_features.items():\n",
    "    print(len(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>items</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>view count</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tnTPaLOaHz8</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 12920, '...</td>\n",
       "      <td>$10,000 Every Day You Survive In A Grocery Store</td>\n",
       "      <td>I didn’t expect him to stay that long \\nShop K...</td>\n",
       "      <td>217172859</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wdjh81uH6FU</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 9390, 'i...</td>\n",
       "      <td>$1 vs $10,000,000 Job!</td>\n",
       "      <td>I can’t believe they actually hired me lol\\nTr...</td>\n",
       "      <td>155154041</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7dYTw-jAYkY</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 11200, '...</td>\n",
       "      <td>I Spent 7 Days Buried Alive</td>\n",
       "      <td>Please don't try this at home lol\\nVerizon 5G ...</td>\n",
       "      <td>152864305</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mwKJfNYwvm8</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 6300, 'i...</td>\n",
       "      <td>I Built 100 Wells In Africa</td>\n",
       "      <td>Click the link below to donate \\nhttps://www.b...</td>\n",
       "      <td>165621129</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>QjvpjXdgugA</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 15590, '...</td>\n",
       "      <td>World’s Deadliest Laser Maze!</td>\n",
       "      <td>I can’t believe what happened at the end…\\nDri...</td>\n",
       "      <td>169254119</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>JinpVA6p8Mo</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 3150, 'i...</td>\n",
       "      <td>Snowball Machine Gun- How to make</td>\n",
       "      <td>Here's how to make a Snowball Machine Gun that...</td>\n",
       "      <td>21356779</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>333</td>\n",
       "      <td>FRlbNOno5VA</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 7450, 'i...</td>\n",
       "      <td>BEST Guess Who Strategy- 96% WIN record using ...</td>\n",
       "      <td>Here is a strategy for winning 96% of your com...</td>\n",
       "      <td>28110693</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>nsnyl8llfH4</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 5890, 'i...</td>\n",
       "      <td>1st place Egg Drop project ideas- using SCIENCE</td>\n",
       "      <td>5 designs guaranteed to win 1st place or your ...</td>\n",
       "      <td>37505427</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>8Vc-69M-UWk</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 2260, 'i...</td>\n",
       "      <td>iPhone ATM PIN code hack- HOW TO PREVENT</td>\n",
       "      <td>This is a new way for bad guys to steal your A...</td>\n",
       "      <td>38803285</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>-RjJtO51ykY</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 9590, 'i...</td>\n",
       "      <td>EASY Pinewood Derby Car WINS using Science!!!</td>\n",
       "      <td>7 simple steps that ACTUALLY MATTER to buildin...</td>\n",
       "      <td>30348596</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           id  \\\n",
       "0             0  tnTPaLOaHz8   \n",
       "1             1  Wdjh81uH6FU   \n",
       "2             2  7dYTw-jAYkY   \n",
       "3             3  mwKJfNYwvm8   \n",
       "4             4  QjvpjXdgugA   \n",
       "..          ...          ...   \n",
       "332         332  JinpVA6p8Mo   \n",
       "333         333  FRlbNOno5VA   \n",
       "334         334  nsnyl8llfH4   \n",
       "335         335  8Vc-69M-UWk   \n",
       "336         336  -RjJtO51ykY   \n",
       "\n",
       "                                                 items  \\\n",
       "0    [{'startMillis': 0, 'durationMillis': 12920, '...   \n",
       "1    [{'startMillis': 0, 'durationMillis': 9390, 'i...   \n",
       "2    [{'startMillis': 0, 'durationMillis': 11200, '...   \n",
       "3    [{'startMillis': 0, 'durationMillis': 6300, 'i...   \n",
       "4    [{'startMillis': 0, 'durationMillis': 15590, '...   \n",
       "..                                                 ...   \n",
       "332  [{'startMillis': 0, 'durationMillis': 3150, 'i...   \n",
       "333  [{'startMillis': 0, 'durationMillis': 7450, 'i...   \n",
       "334  [{'startMillis': 0, 'durationMillis': 5890, 'i...   \n",
       "335  [{'startMillis': 0, 'durationMillis': 2260, 'i...   \n",
       "336  [{'startMillis': 0, 'durationMillis': 9590, 'i...   \n",
       "\n",
       "                                                 title  \\\n",
       "0     $10,000 Every Day You Survive In A Grocery Store   \n",
       "1                               $1 vs $10,000,000 Job!   \n",
       "2                          I Spent 7 Days Buried Alive   \n",
       "3                          I Built 100 Wells In Africa   \n",
       "4                        World’s Deadliest Laser Maze!   \n",
       "..                                                 ...   \n",
       "332                  Snowball Machine Gun- How to make   \n",
       "333  BEST Guess Who Strategy- 96% WIN record using ...   \n",
       "334    1st place Egg Drop project ideas- using SCIENCE   \n",
       "335           iPhone ATM PIN code hack- HOW TO PREVENT   \n",
       "336      EASY Pinewood Derby Car WINS using Science!!!   \n",
       "\n",
       "                                           description  view count  \\\n",
       "0    I didn’t expect him to stay that long \\nShop K...   217172859   \n",
       "1    I can’t believe they actually hired me lol\\nTr...   155154041   \n",
       "2    Please don't try this at home lol\\nVerizon 5G ...   152864305   \n",
       "3    Click the link below to donate \\nhttps://www.b...   165621129   \n",
       "4    I can’t believe what happened at the end…\\nDri...   169254119   \n",
       "..                                                 ...         ...   \n",
       "332  Here's how to make a Snowball Machine Gun that...    21356779   \n",
       "333  Here is a strategy for winning 96% of your com...    28110693   \n",
       "334  5 designs guaranteed to win 1st place or your ...    37505427   \n",
       "335  This is a new way for bad guys to steal your A...    38803285   \n",
       "336  7 simple steps that ACTUALLY MATTER to buildin...    30348596   \n",
       "\n",
       "          Category  \n",
       "0    Entertainment  \n",
       "1    Entertainment  \n",
       "2    Entertainment  \n",
       "3    Entertainment  \n",
       "4    Entertainment  \n",
       "..             ...  \n",
       "332  Howto & Style  \n",
       "333  Howto & Style  \n",
       "334  Howto & Style  \n",
       "335  Howto & Style  \n",
       "336  Howto & Style  \n",
       "\n",
       "[337 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = raw_data['title']\n",
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>items</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>view count</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wdjh81uH6FU</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 9390, 'i...</td>\n",
       "      <td>$1 vs $10,000,000 Job!</td>\n",
       "      <td>I can’t believe they actually hired me lol\\nTr...</td>\n",
       "      <td>155154041</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7dYTw-jAYkY</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 11200, '...</td>\n",
       "      <td>I Spent 7 Days Buried Alive</td>\n",
       "      <td>Please don't try this at home lol\\nVerizon 5G ...</td>\n",
       "      <td>152864305</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mwKJfNYwvm8</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 6300, 'i...</td>\n",
       "      <td>I Built 100 Wells In Africa</td>\n",
       "      <td>Click the link below to donate \\nhttps://www.b...</td>\n",
       "      <td>165621129</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>QjvpjXdgugA</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 15590, '...</td>\n",
       "      <td>World’s Deadliest Laser Maze!</td>\n",
       "      <td>I can’t believe what happened at the end…\\nDri...</td>\n",
       "      <td>169254119</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3ryID_SwU5E</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 10560, '...</td>\n",
       "      <td>$1 vs $100,000,000 House!</td>\n",
       "      <td>I can’t believe how expensive the last house i...</td>\n",
       "      <td>200283545</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>332</td>\n",
       "      <td>JinpVA6p8Mo</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 3150, 'i...</td>\n",
       "      <td>Snowball Machine Gun- How to make</td>\n",
       "      <td>Here's how to make a Snowball Machine Gun that...</td>\n",
       "      <td>21356779</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>333</td>\n",
       "      <td>FRlbNOno5VA</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 7450, 'i...</td>\n",
       "      <td>BEST Guess Who Strategy- 96% WIN record using ...</td>\n",
       "      <td>Here is a strategy for winning 96% of your com...</td>\n",
       "      <td>28110693</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>334</td>\n",
       "      <td>nsnyl8llfH4</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 5890, 'i...</td>\n",
       "      <td>1st place Egg Drop project ideas- using SCIENCE</td>\n",
       "      <td>5 designs guaranteed to win 1st place or your ...</td>\n",
       "      <td>37505427</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>335</td>\n",
       "      <td>8Vc-69M-UWk</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 2260, 'i...</td>\n",
       "      <td>iPhone ATM PIN code hack- HOW TO PREVENT</td>\n",
       "      <td>This is a new way for bad guys to steal your A...</td>\n",
       "      <td>38803285</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>336</td>\n",
       "      <td>-RjJtO51ykY</td>\n",
       "      <td>[{'startMillis': 0, 'durationMillis': 9590, 'i...</td>\n",
       "      <td>EASY Pinewood Derby Car WINS using Science!!!</td>\n",
       "      <td>7 simple steps that ACTUALLY MATTER to buildin...</td>\n",
       "      <td>30348596</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           id  \\\n",
       "0             1  Wdjh81uH6FU   \n",
       "1             2  7dYTw-jAYkY   \n",
       "2             3  mwKJfNYwvm8   \n",
       "3             4  QjvpjXdgugA   \n",
       "4             5  3ryID_SwU5E   \n",
       "..          ...          ...   \n",
       "328         332  JinpVA6p8Mo   \n",
       "329         333  FRlbNOno5VA   \n",
       "330         334  nsnyl8llfH4   \n",
       "331         335  8Vc-69M-UWk   \n",
       "332         336  -RjJtO51ykY   \n",
       "\n",
       "                                                 items  \\\n",
       "0    [{'startMillis': 0, 'durationMillis': 9390, 'i...   \n",
       "1    [{'startMillis': 0, 'durationMillis': 11200, '...   \n",
       "2    [{'startMillis': 0, 'durationMillis': 6300, 'i...   \n",
       "3    [{'startMillis': 0, 'durationMillis': 15590, '...   \n",
       "4    [{'startMillis': 0, 'durationMillis': 10560, '...   \n",
       "..                                                 ...   \n",
       "328  [{'startMillis': 0, 'durationMillis': 3150, 'i...   \n",
       "329  [{'startMillis': 0, 'durationMillis': 7450, 'i...   \n",
       "330  [{'startMillis': 0, 'durationMillis': 5890, 'i...   \n",
       "331  [{'startMillis': 0, 'durationMillis': 2260, 'i...   \n",
       "332  [{'startMillis': 0, 'durationMillis': 9590, 'i...   \n",
       "\n",
       "                                                 title  \\\n",
       "0                               $1 vs $10,000,000 Job!   \n",
       "1                          I Spent 7 Days Buried Alive   \n",
       "2                          I Built 100 Wells In Africa   \n",
       "3                        World’s Deadliest Laser Maze!   \n",
       "4                            $1 vs $100,000,000 House!   \n",
       "..                                                 ...   \n",
       "328                  Snowball Machine Gun- How to make   \n",
       "329  BEST Guess Who Strategy- 96% WIN record using ...   \n",
       "330    1st place Egg Drop project ideas- using SCIENCE   \n",
       "331           iPhone ATM PIN code hack- HOW TO PREVENT   \n",
       "332      EASY Pinewood Derby Car WINS using Science!!!   \n",
       "\n",
       "                                           description  view count  \\\n",
       "0    I can’t believe they actually hired me lol\\nTr...   155154041   \n",
       "1    Please don't try this at home lol\\nVerizon 5G ...   152864305   \n",
       "2    Click the link below to donate \\nhttps://www.b...   165621129   \n",
       "3    I can’t believe what happened at the end…\\nDri...   169254119   \n",
       "4    I can’t believe how expensive the last house i...   200283545   \n",
       "..                                                 ...         ...   \n",
       "328  Here's how to make a Snowball Machine Gun that...    21356779   \n",
       "329  Here is a strategy for winning 96% of your com...    28110693   \n",
       "330  5 designs guaranteed to win 1st place or your ...    37505427   \n",
       "331  This is a new way for bad guys to steal your A...    38803285   \n",
       "332  7 simple steps that ACTUALLY MATTER to buildin...    30348596   \n",
       "\n",
       "          Category  \n",
       "0    Entertainment  \n",
       "1    Entertainment  \n",
       "2    Entertainment  \n",
       "3    Entertainment  \n",
       "4    Entertainment  \n",
       "..             ...  \n",
       "328  Howto & Style  \n",
       "329  Howto & Style  \n",
       "330  Howto & Style  \n",
       "331  Howto & Style  \n",
       "332  Howto & Style  \n",
       "\n",
       "[333 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of video IDs to remove\n",
    "vid_ids = frames_features.keys()\n",
    "\n",
    "# Filter the DataFrame to exclude rows with the specified video IDs\n",
    "raw_data = raw_data[raw_data['id'].isin(vid_ids)]\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tnTPaLOaHz8'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_key_list = list(frames_features.keys())\n",
    "frames_key_list[255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>length_title</th>\n",
       "      <th>view count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wdjh81uH6FU</td>\n",
       "      <td>$1 vs $10,000,000 Job!</td>\n",
       "      <td>4</td>\n",
       "      <td>155681496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7dYTw-jAYkY</td>\n",
       "      <td>I Spent 7 Days Buried Alive</td>\n",
       "      <td>6</td>\n",
       "      <td>153336529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mwKJfNYwvm8</td>\n",
       "      <td>I Built 100 Wells In Africa</td>\n",
       "      <td>6</td>\n",
       "      <td>165967222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QjvpjXdgugA</td>\n",
       "      <td>World’s Deadliest Laser Maze!</td>\n",
       "      <td>4</td>\n",
       "      <td>169840468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3ryID_SwU5E</td>\n",
       "      <td>$1 vs $100,000,000 House!</td>\n",
       "      <td>4</td>\n",
       "      <td>200784748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>JinpVA6p8Mo</td>\n",
       "      <td>Snowball Machine Gun- How to make</td>\n",
       "      <td>6</td>\n",
       "      <td>21369170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>FRlbNOno5VA</td>\n",
       "      <td>BEST Guess Who Strategy- 96% WIN record using ...</td>\n",
       "      <td>9</td>\n",
       "      <td>28131975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>nsnyl8llfH4</td>\n",
       "      <td>1st place Egg Drop project ideas- using SCIENCE</td>\n",
       "      <td>8</td>\n",
       "      <td>37534623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>8Vc-69M-UWk</td>\n",
       "      <td>iPhone ATM PIN code hack- HOW TO PREVENT</td>\n",
       "      <td>8</td>\n",
       "      <td>38813844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-RjJtO51ykY</td>\n",
       "      <td>EASY Pinewood Derby Car WINS using Science!!!</td>\n",
       "      <td>7</td>\n",
       "      <td>30351978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "0    Wdjh81uH6FU                             $1 vs $10,000,000 Job!   \n",
       "1    7dYTw-jAYkY                        I Spent 7 Days Buried Alive   \n",
       "2    mwKJfNYwvm8                        I Built 100 Wells In Africa   \n",
       "3    QjvpjXdgugA                      World’s Deadliest Laser Maze!   \n",
       "4    3ryID_SwU5E                          $1 vs $100,000,000 House!   \n",
       "..           ...                                                ...   \n",
       "328  JinpVA6p8Mo                  Snowball Machine Gun- How to make   \n",
       "329  FRlbNOno5VA  BEST Guess Who Strategy- 96% WIN record using ...   \n",
       "330  nsnyl8llfH4    1st place Egg Drop project ideas- using SCIENCE   \n",
       "331  8Vc-69M-UWk           iPhone ATM PIN code hack- HOW TO PREVENT   \n",
       "332  -RjJtO51ykY      EASY Pinewood Derby Car WINS using Science!!!   \n",
       "\n",
       "     length_title  view count  \n",
       "0               4   155681496  \n",
       "1               6   153336529  \n",
       "2               6   165967222  \n",
       "3               4   169840468  \n",
       "4               4   200784748  \n",
       "..            ...         ...  \n",
       "328             6    21369170  \n",
       "329             9    28131975  \n",
       "330             8    37534623  \n",
       "331             8    38813844  \n",
       "332             7    30351978  \n",
       "\n",
       "[333 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_title_view_count = length_title_view_count[length_title_view_count['id'].isin(vid_ids)]\n",
    "length_title_view_count = length_title_view_count.reset_index(drop=True)\n",
    "length_title_view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                 $1 vs $10,000,000 Job!\n",
      "1                            I Spent 7 Days Buried Alive\n",
      "2                            I Built 100 Wells In Africa\n",
      "3                          World’s Deadliest Laser Maze!\n",
      "4                              $1 vs $100,000,000 House!\n",
      "                             ...                        \n",
      "328                    Snowball Machine Gun- How to make\n",
      "329    BEST Guess Who Strategy- 96% WIN record using ...\n",
      "330      1st place Egg Drop project ideas- using SCIENCE\n",
      "331             iPhone ATM PIN code hack- HOW TO PREVENT\n",
      "332        EASY Pinewood Derby Car WINS using Science!!!\n",
      "Name: title, Length: 333, dtype: object\n",
      "Sentence: $1 vs $10,000,000 Job!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 7 Days Buried Alive\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Built 100 Wells In Africa\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World’s Deadliest Laser Maze!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $1 vs $100,000,000 House!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Most Dangerous Trap!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $1 vs $100,000,000 Car!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Lamborghini Vs World's Largest Shredder\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Every Country On Earth Fights For $250,000!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $1 vs $250,000 Vacation!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 7 Days Stranded At Sea\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Train Vs Giant Pit\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $1 vs $1,000,000,000 Yacht!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Ages 1 - 100 Fight For $500,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 1,000 Deaf People Hear For The First Time\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Paid A Real Assassin To Try To Kill Me\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 1,000 Blind People See For The First Time\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived 50 Hours In Antarctica\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Hydraulic Press Vs Lamborghini\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 100 Kids Vs 100 Adults For $500,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Take Hand Off Jet, Keeps It!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $1 vs $1,000,000 Hotel Room!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Survive 100 Days In Circle, Win $500,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Hunted 100 People!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived A Plane Crash\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave My 100,000,000th Subscriber An Island\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 100 Boys Vs 100 Girls For $500,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Didn’t Eat Food For 30 Days\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Built Willy Wonka's Chocolate Factory!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $10,000 Every Day You Survive Prison\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would You Swim With Sharks For $100,000?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World’s Most Dangerous Escape Room!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Extreme $1,000,000 Hide And Seek\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $1,000,000 Influencer Tournament!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Got Hunted By The Military\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $456,000 Squid Game In Real Life!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Cleaned The World’s Dirtiest Beach #TeamSeas\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Take Hand Off Lamborghini, Keeps It\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: First To Rob Bank Wins $100,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Extreme $500,000 Game Of Tag!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Got Hunted By The FBI\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: If You Can Carry $1,000,000 You Keep It!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would YOU Quit School For $100,000?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived 50 Hours In A Maximum Security Prison\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Hit The Target, Win $300,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Anything You Can Fit In The Triangle I’ll Pay For\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Got Hunted By A Real Bounty Hunter\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Extreme $100,000 Game of Tag!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would You Sit In Snakes For $10,000?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought The World's Largest Mystery Box! ($500,000)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 50 Hours Buried Alive\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Offering People $100,000 To Quit Their Job\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Sold My House For $1\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Donated $300,000 To People In Need\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Ate $100,000 Golden Ice Cream\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought Everything In 5 Stores\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Youtube Rewind 2020, Thank God It's Over\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Put 1,000,000,000 Christmas Lights On A House (World Record)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Opened A Restaurant That Pays You To Eat At It\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave People $1,000,000 But ONLY 1 Minute To Spend It!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Steal This $100,000 Diamond, You Keep It\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Press This Button To Win $100,000!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived 24 Hours Straight In Ice\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Uber’d People And Let Them Keep The Car\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Filled My Brother’s House With Slime & Bought Him A New One\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Hi Me In 5 Years\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would You Rather Have A Giant Diamond or $100,000?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave My 40,000,000th Subscriber 40 Cars\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Why I Haven’t Been Uploading\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Get This Random Person 1,000,000 Subscribers\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would YOU Rather Have A Lamborghini or This House?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought A Private Island\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent $1,000,000 On Lottery Tickets and WON\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Ate The World’s Largest Slice Of Pizza\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Adopted EVERY Dog In A Dog Shelter\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought The World's Largest Firework ($600,000)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Broke Into A House\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would You Rather Have $100,000 OR This Mystery Key?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Built The World's Largest Lego Tower\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 50 Hours In Solitary Confinement\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: If You Click This Video I'll Give My Friend .001$\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave $200,000 To People Who Lost Their Jobs (Corona Virus)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 24 Hours In A Doomsday Bunker\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Giving $1,000,000 Of Food To People In Need\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $70,000 Extreme Hide And Seek - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Anything You Can Fit In The Circle I’ll Pay For\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Lamborghini Race, Winner Keeps Lamborghini\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave My Credit Card To Random People\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Went Back To Boy Scouts For A Day\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $60,000 Extreme Hide And Seek - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Giving 10,000 Presents To Kids For Christmas\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Spending $1,000,000 In 24 Hours\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Take Hand Off $1,000,000 Keeps It\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Stop Riding Bike Wins $1,000,000 (Part 4)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Toilet Wins $1,000,000 (Part 3)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Ordered Pizza And Tipped The House\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last to Stop Swinging Wins $1,000,000 (Part 2)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $50,000 Game Of Extreme Hide And Seek - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Opened A FREE BANK\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Going Around A Ferris Wheel 1,000 Times Straight\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Fall Wins $1,000,000 (Part 1)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surviving 24 Hours Straight In The Bermuda Triangle\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent $100,000 On Lottery Tickets And Won!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Planting 20,000,000 Trees, My Biggest Project Ever!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Take Hand Off Boat, Keeps It\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Searched 100 Dumpsters, Here's What I Found\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Going Through The Same Drive Thru 1,000 Times\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Donating $100,000 To Random Streamers\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surviving 24 Hours Straight In A Rain Forest\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Ramen Noodle Pool Wins $20,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Anything You Can Carry, I'll Pay For #2\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave My Brother 24 Hours To Spend $100,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Pool Of $20,000 Keeps It\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surviving 24 Hours On A Deserted Island\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Roller Coaster Wins $20,000 - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Won Every Prize At A Theme Park\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Destroying My Friend's Car And Surprising Him With A New One\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 24 Hours Straight At Area 51\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Can 50,000 Magnets Catch A Cannon Ball?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest Game Of Dodgeball\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Revolving Door Wins $50,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Tipping Waitresses With Real Gold Bars\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Opened The World's First FREE Store\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Spending 24 Hours On Top Of A Mountain\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave VR Wins $20,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Stop Running Wins $20,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Paying People $10,000 To Eat Ghost Pepper\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 24 Hours In The Most Haunted Place On Earth\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought Everything In A Store - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest Bowl Of Cereal\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Spending 24 Hours In A City With No Laws\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Giving $10,000 To Random People And Saying Nothing\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Molten Lava Vs Giant Ice Block Experiment\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Anything You Can Carry, I'll Pay For Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Homeless Man Buys A Lamborghini\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Playing Battleship With Real Ships\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Donating $100,000 To Shroud In Real Life\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave The Tesla, Keeps It Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Donating $100,000 To Streamers With 0 Viewers\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surviving 24 Hours Straight In A Desert\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $200,000 Youtuber Battle Royale\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surprising Strangers With 100 Zombies - Experiment\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave A Homeless Man A Home\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Standing Still For 24 Hours Straight - Statue Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Giant Monopoly Game With Real Money\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 24 Hours Straight In Insane Asylum\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Advertised Pewdiepie At The Super Bowl\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Went Back To 1st Grade For A Day\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Opened The World’s Cheapest Store\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Put 10 Million Legos in Friend's House\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Make This Video The Most Liked Video On Youtube\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 20,000 Magnets Vs A Car\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Eating A $10,000 Golden Steak (24k Gold)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Take Hand Off House Keeps It!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave Him One Hour To Spend $100,000!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How I Gave Away $1,000,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Giving $100,000 To A Homeless Person\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 24 Hours Straight In Prison - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Donating $10000 To Pewdiepie\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last Youtuber To Leave Wins $100,000 - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Put Millions Of Pennies In My Friends Backyard\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surprising TFue With A Fortnite Battle Bus In Real Life\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Built A Giant House Using Only Legos\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Slime Pit Wins $20,000 - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Destroyed Friend's House And Bought Him A New One\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Put 100 Million Orbeez In My Friend's Backyard\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Spending $40,000 In One Hour Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Giving My 10,000,000th Subscriber 10,000,000 ___\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $10,000 Games Of Rock Paper Scissors\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Remove Hand, Gets Lamborghini Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: You Pick The Right Cup, You Win $100,000!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought Every Billboard In My City For This\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Ordering Water Then Tipping $30,000\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent $50,000 On Lottery Tickets And Won ____\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Last To Leave Circle Wins $10,000 - Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent 24 Hours Straight In Slime\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surprising Tfue With $10,000 Live - Fortnite\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Spent $30,000 On Lottery Tickets And Won ____\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Flat Earth PROVEN By Independent Research\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Things That SHOULDN'T Be Sold On Amazon\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Surprising My 8,000,000th Subscriber With 8,000,000 ___\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Donated $25,000 To Random Kids Streaming Fortnite\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Hope This Magic Trick Works\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Can A Glowing 1000 Degree Sword Slice A Car In Half?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Rocket League In Real Life!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Destroying My Friend's Car And Surprising Him With A New One - Slime\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Spending 24 Hours Straight Under Water Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Attempting The Impossible Maze - $10,000 Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Donating $100,000 To A Random Fortnite Streamer\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Moving 10 Pounds Using ONLY Sound\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave My 6,000,000th Subscriber 6,000,000 ____\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Can 1,000 Fans At Max Speed Push A Car?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Ubered Random People In A Tank\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Hottest Substance Vs Coldest Substance\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: The Real Way Dinosaurs Went Extinct\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Donated $1000 Every Time She Blinked - Fortnite Streamers\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Built A Working Car Using Only LEGOS\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Do Water Repellent Shoes Actually Work?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: We Drove 3,000 Miles For The World's Best Burger\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave My 5,000,000th Subscriber 5,000,000 ______\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Made Money Grow On Trees\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Took Apart My Friends Car And Put It In His Room\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How Many Rubber Bands Does It Take To Snap A Safe?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Pulling Cars Over Using A Toy Police Car\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave $500,000 To Random People\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How Many Toy Cars Does It Take To Pull A Real Car?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave $20,000 To People From An Ice Cream Truck\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: $10000 Ice Sculpture Vs Flame\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Tying My Shoes In Every State (World Record)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Bad Uber Driver Prank!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Tried The Most Dangerous Alarm Clocks\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Stole America’s Got Talent!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Brought 50 Competitive Eaters To A Buffet!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Fake Tour Guide Prank!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived 24 Hours In Australia\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 24 Hours In The Most Dangerous Underground City\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Tested The World’s Most Expensive Hotel\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived The World's Largest Water Park\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Bought The Most Expensive Plane Ticket!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Survived Overnight In Shrek’s Swamp\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Crossed Italy In A Perfectly Straight Line - Day 6\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Crossed Switzerland In A Perfectly Straight Line - Day 5\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Crossed Switzerland In A Perfectly Straight Line - Day 4\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Crossed France In A Perfectly Straight Line - Day 3\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Crossed The UK In A Perfectly Straight Line - Day 2\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Crossed Ireland In A Perfectly Straight Line - Day 1\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Have To Delete My Channel.\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Tried Banned Inventions\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Try Not To Scream: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Tried Every IMPOSSIBLE Sport\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Sneaking Into Celebrity Pools\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Tried The World’s Fastest Vehicles\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Hired 100 Fake Paparazzi\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Tried Every Drive Thru\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Invisible Driver Prank\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Extreme Dares In Public!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 100 Dates In 24 Hours!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I ACTUALLY Got MrBeast Arrested\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Escaped Prisoner Prank\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Ai Girl Speed Dates 10 YouTubers\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Human Hamster Wheel Vs Tesla: Can I Power It?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Walking On Water Prank\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Will An Ex Convict Return $20,000 Rolex?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Trapped 25 Celebrities In A Box\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Made The World's Largest Pizza (132 Feet)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Exposed Strangers Lying In Public\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Truth Or Dare: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Would You Rather: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Capture The Flag: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 1 Nerd VS 100 Supermodels\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Hit 10,000,000 Subscribers\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Caught Strangers Lying In Public\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Trapped 100 Strangers In Complete Darkness\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Try Not To Laugh: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Never Have I Ever: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Built A REAL Primitive Survival Mansion\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: What Happens If You Hire 100 Bodyguards?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Could You Survive On Mars?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Trapped 25 Strangers In A Box\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Escape or Die: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Ordered 10,000 Amazon Packages!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Humans VS Robots: 100 Experiments\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: If You Scream, You Lose: IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 24 Hours To Live: Challenge\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 100 Dates In 24 Hours!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: AGE 12 TO MARRIED – I Took A Photo Every Day\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: CECI EST UNE FOIRE AUX QUESTIONS #2 (FAQ Squeezie)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: If Two Girls Falling Asleep on You at the Same Time | Prank 当两个姑娘同时靠在自己肩膀上睡着了，路人小哥坐过了站\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Car Thief Gets Instant Karma (the FINAL Glitterbomb 6.0)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Octopus vs Underwater Maze\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Acid vs Lava- Testing Liquids That Melt Everything\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Candy Thieves vs Rigged Candy Bowl\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World’s Smallest Nerf Gun Shoots an Ant\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How to Escape a Police Sniffing Dog\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: I Gave the 2023 MIT Commencement Speech\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: This Ball is Impossible to Hit\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Amazing Invention- This Drone Will Change Everything\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Bed Bugs- What You've Been Told is Totally False\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Car Thieves vs the Almost Final GlitterBomb 5.0\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Backyard Squirrelympics 3.0- The Summer Games\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Beating 5 Scam Arcade Games with Science\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: My Secret Warehouse Tour\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Pranks Destroy Scam Callers- GlitterBomb Payback\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Robot Piano Catches Fire Playing Rush E (World’s Hardest Song)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest T-Shirt Cannon (breaks the roof)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: EXPLODING Glitter Bomb 4.0 vs. Package Thieves\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Tallest Elephant Toothpaste Volcano\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World Record Domino Robot (100k dominoes in 24hrs)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Shark vs. GoPro\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Backyard Squirrel Maze 2.0- The Walnut Heist\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Glitterbomb Trap Catches Phone Scammer (who gets arrested)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Glitterbomb 3.0 vs. Porch Pirates\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Shark Attack Test- Human Blood vs. Fish Blood\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Backyard Squirrel Maze 1.0- Ninja Warrior Course\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How To See Germs Spread Experiment (Coronavirus)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: CAR vs. WORLD’S STRONGEST TRAMPOLINE- 150ft (45m) drop\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Feeding Bill Gates a Fake Burger (to save the world)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Glitter Bomb 2.0 vs Porch Pirates\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's First Automatic Strike Bowling Ball\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest Elephant Toothpaste Experiment\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Testing if Sharks Can Smell a Drop of Blood\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Stealing Baseball Signs with a Phone (Machine Learning)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Rocket Powered Golf Club at 100,000 FPS\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Drinking Nasty Swamp Water (to save the world)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Glitter Bomb 1.0 vs Porch Pirates\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest Horn Shatters Glass\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Playing Card Machine Gun- Card Throwing Trick Shots\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Flying Phone Scam Exposed (so I built a REAL one)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Beat Any Escape Room- 10 proven tricks and tips\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Rock Skip Robot- The Science of Perfect Rock Skipping\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 1st place Mousetrap Car Ideas\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: This Arcade Game is a SCAM (I have proof)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Liquid Sand Hot Tub- Fluidized air bed\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Measuring How Much Pee Is In Your Pool\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest Super Soaker\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: NICEST Car Horn Ever- DIY\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Hot Wheels STUNT RACE- Slow Mo (2500 FPS)\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Automatic Bullseye, MOVING Dartboard\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How to save 51 billion lives for 68 cents with simple Engineering\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Myth-testing Christmas movies with Science Experiments\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How to CHEER THE LOUDEST using SCIENCE!\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: PAINT Super Soaker Battle (w/ Colin Furze)- Splatoon IRL\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: GLOWING WALL DIY- EASY and AWESOME\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Bare Hand Bottle Busting- Science Investigation\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 25 Million Orbeez in a pool- Do you sink or float?\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: World's Largest Nerf Gun\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: How to Survive a Grenade Blast\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Solar System Model From a Drone's View\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: Snowball Machine Gun- How to make\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: BEST Guess Who Strategy- 96% WIN record using MATH\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: 1st place Egg Drop project ideas- using SCIENCE\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: iPhone ATM PIN code hack- HOW TO PREVENT\n",
      "Embedding: (384,)\n",
      "\n",
      "Sentence: EASY Pinewood Derby Car WINS using Science!!!\n",
      "Embedding: (384,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Our sentences we like to encode\n",
    "sentences = raw_data['title']\n",
    "print(sentences)\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "vocab_embeds = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, vocab_embeds):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding.shape)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999755521558455"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.column_stack((length_title_view_count['length_title'], vocab_embeds))\n",
    "y = np.array(length_title_view_count['view count'])\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2170e9fad10>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fae00>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9faef0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fafe0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb0d0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb1c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb2b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb3a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb490>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb580>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb670>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb730>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb820>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fb910>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fba00>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fbaf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fbbe0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fbcd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fbdc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fbeb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9fbfa0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea340d0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea341c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea342b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea343a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34490>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34580>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34670>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34760>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34850>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34940>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34a30>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34b20>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34c10>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34d00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34df0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34ee0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea34fd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea350c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea351b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea352a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35390>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35480>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35570>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35660>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35750>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35840>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35930>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35a20>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35b10>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35c00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35cf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35de0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35ed0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea35fc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea360b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea361a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36290>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36380>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36470>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36560>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36650>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36740>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36830>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36920>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36a10>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36b00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36bf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36ce0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36dd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36ec0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea36fb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea370a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37190>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37280>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37370>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37460>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37550>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37640>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37730>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37820>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37910>,\n",
       " <matplotlib.lines.Line2D at 0x2170e993340>,\n",
       " <matplotlib.lines.Line2D at 0x2170e9932b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37ac0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37bb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37ca0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37d90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37e80>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea37f70>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea540a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54190>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54280>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54370>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54460>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54550>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54640>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54730>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54820>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54910>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54a00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54af0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54be0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54cd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54dc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54eb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea54fa0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55090>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55180>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55270>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55360>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55450>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55540>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55630>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55720>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55810>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55900>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea559f0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55ae0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55bd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55cc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55db0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55ea0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea55f90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56080>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56170>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56260>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56350>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56440>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56530>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56620>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56710>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56800>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea568f0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea569e0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56ad0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56bc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56cb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56da0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56e90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea56f80>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57070>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57160>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57250>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57340>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57430>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57520>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57610>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57700>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea577f0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea578e0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea579d0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57ac0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57bb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57ca0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57d90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57e80>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea57f70>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea740a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74190>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74280>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74370>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74460>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74550>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74640>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74730>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74820>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74910>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74a00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74af0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74be0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74cd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74dc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74eb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea74fa0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75090>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75180>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75270>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75360>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75450>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75540>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75630>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75720>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75810>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75900>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea759f0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75ae0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75bd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75cc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75db0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75ea0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea75f90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76080>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76170>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76260>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76350>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76440>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76530>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76620>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76710>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76800>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea768f0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea769e0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76ad0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76bc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76cb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76da0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76e90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea76f80>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77070>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77160>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77250>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77340>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77430>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77520>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77610>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77700>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea777f0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea778e0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea779d0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77ac0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77bb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77ca0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77d90>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77e80>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea77f70>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea980a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98190>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98280>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98370>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98460>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98550>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98640>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98730>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98820>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98910>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98a00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98af0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98be0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98cd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98dc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98eb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea98fa0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99090>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99180>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99270>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99360>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99450>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99570>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99660>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99750>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99840>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99930>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99a20>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99b10>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99c00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99cf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99de0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99ed0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea99fc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a0b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a1a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a290>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a380>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a470>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a560>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a650>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a740>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a830>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9a920>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9aa10>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9ab00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9abf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9ace0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9add0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9aec0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9afb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b0a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b190>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b280>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b370>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b460>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b550>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b640>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b730>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b820>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9b910>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9ba00>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9baf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9bbe0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9bcd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9bdc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9beb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170ea9bfa0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc0d0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc1c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc2b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc3a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc490>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc580>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc670>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc760>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc850>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabc940>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabca30>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabcb20>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabcc10>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabcd00>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabcdf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabcee0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabcfd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd0c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd1b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd2a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd390>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd480>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd570>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd660>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd750>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd840>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabd930>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabda20>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabdb10>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabdc00>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabdcf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabdde0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabded0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabdfc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe0b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe1a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe290>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe380>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe470>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe560>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe650>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe740>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe830>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabe920>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabea10>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabeb00>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabebf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabece0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabedd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabeec0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabefb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf0a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf190>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf280>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf370>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf460>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf550>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf640>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf730>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf820>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabf910>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabfa00>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabfaf0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabfbe0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabfcd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabfdc0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabfeb0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eabffa0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae00d0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae01c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae02b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae03a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0490>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0580>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0670>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0760>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0850>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0940>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0a30>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0b20>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0c10>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0d00>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0df0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0ee0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae0fd0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae10c0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae11b0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae12a0>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae1390>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae1480>,\n",
       " <matplotlib.lines.Line2D at 0x2170eae1570>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, y, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10.4155, -15.8470,  -3.0060,  36.6296], grad_fn=<SqueezeBackward0>)\n",
      "tensor([-10.2468,  21.4402,  17.1614,  -2.5121], grad_fn=<SqueezeBackward0>)\n",
      "tensor([-3.8513, 22.1945,  9.5547,  0.2976], grad_fn=<SqueezeBackward0>)\n",
      "tensor([11.9871,  4.4548,  6.9139,  7.0745], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 6.0953,  0.0817, 14.1850,  9.8399], grad_fn=<SqueezeBackward0>)\n",
      "tensor([37.3916,  6.5000, -5.4060, -7.0122], grad_fn=<SqueezeBackward0>)\n",
      "tensor([10.7251, -3.2230,  5.1936, 12.1205], grad_fn=<SqueezeBackward0>)\n",
      "tensor([13.2402, 25.7513,  4.1152, 13.7084], grad_fn=<SqueezeBackward0>)\n",
      "tensor([18.0846, 19.9374, 18.4645, 14.5768], grad_fn=<SqueezeBackward0>)\n",
      "tensor([23.3571, 29.0072, 15.5795, 14.1342], grad_fn=<SqueezeBackward0>)\n",
      "tensor([24.9246, 32.2976, 13.8975, 21.1825], grad_fn=<SqueezeBackward0>)\n",
      "tensor([40.2876, 19.0169, 22.4824,  8.7618], grad_fn=<SqueezeBackward0>)\n",
      "tensor([27.3645, 14.2626, 40.2571,  7.5717], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 8.3340, 19.0774, 20.5369, 25.7135], grad_fn=<SqueezeBackward0>)\n",
      "tensor([27.7257,  7.9226, 33.4011, 12.2944], grad_fn=<SqueezeBackward0>)\n",
      "tensor([19.4721, 19.2830, 29.2586, 28.7624], grad_fn=<SqueezeBackward0>)\n",
      "tensor([21.5847, 31.8636, 47.9226, 40.8229], grad_fn=<SqueezeBackward0>)\n",
      "tensor([17.1397, 55.4740, 21.9093, 21.6636], grad_fn=<SqueezeBackward0>)\n",
      "tensor([18.1306, 22.8105, 20.4635, 19.5584], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 8.3220, 28.8141, 11.8685, 20.7045], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 23.6103,  35.3541, -34.4028,  27.1233], grad_fn=<SqueezeBackward0>)\n",
      "tensor([24.1479,  8.5020, 37.4011, 24.4727], grad_fn=<SqueezeBackward0>)\n",
      "tensor([32.0474, 25.8288, 41.7638, 32.4665], grad_fn=<SqueezeBackward0>)\n",
      "tensor([27.1128, 29.2912, 11.8364, 24.9713], grad_fn=<SqueezeBackward0>)\n",
      "tensor([28.2134, 23.1743, 19.1791, 50.6107], grad_fn=<SqueezeBackward0>)\n",
      "tensor([41.1703, 49.1661, 36.3744, 30.6676], grad_fn=<SqueezeBackward0>)\n",
      "tensor([31.7530, 28.5472, 59.8525, 29.4986], grad_fn=<SqueezeBackward0>)\n",
      "tensor([38.8570, 12.7103, 31.7488, 43.8956], grad_fn=<SqueezeBackward0>)\n",
      "tensor([42.7262, 44.0786, 35.1312, 16.9654], grad_fn=<SqueezeBackward0>)\n",
      "tensor([38.6921, 36.3629, 35.6632, 12.7660], grad_fn=<SqueezeBackward0>)\n",
      "tensor([45.9857, 39.5731, 44.2248, 26.9112], grad_fn=<SqueezeBackward0>)\n",
      "tensor([51.2157, 20.3786, 46.0328, 52.3852], grad_fn=<SqueezeBackward0>)\n",
      "tensor([34.1294, 43.4001, 28.6355, 23.5929], grad_fn=<SqueezeBackward0>)\n",
      "tensor([47.7784, 29.5439, 61.4009, 50.7023], grad_fn=<SqueezeBackward0>)\n",
      "tensor([50.2167, 43.1154, 40.5564, 31.7973], grad_fn=<SqueezeBackward0>)\n",
      "tensor([32.2980, 36.8515, 42.6602, 53.3059], grad_fn=<SqueezeBackward0>)\n",
      "tensor([55.8258, 35.0500, 34.4491, 24.9820], grad_fn=<SqueezeBackward0>)\n",
      "tensor([38.2066, 34.5519, 59.7088, 28.7540], grad_fn=<SqueezeBackward0>)\n",
      "tensor([16.3502, 37.4621, 43.8961, 27.1851], grad_fn=<SqueezeBackward0>)\n",
      "tensor([44.9282, 28.1942, 46.1296, 33.5649], grad_fn=<SqueezeBackward0>)\n",
      "tensor([44.0747, 52.8927, 40.1629, 47.0116], grad_fn=<SqueezeBackward0>)\n",
      "tensor([35.4906, 48.3982, 26.1084, 40.2480], grad_fn=<SqueezeBackward0>)\n",
      "tensor([38.6642, 45.0246, 33.8940, 49.7846], grad_fn=<SqueezeBackward0>)\n",
      "tensor([61.7337, 44.1249, 44.5632, 40.9409], grad_fn=<SqueezeBackward0>)\n",
      "tensor([42.7894, 48.0057, 51.7737, 25.6549], grad_fn=<SqueezeBackward0>)\n",
      "tensor([57.6015, 26.5506, 60.4363, 41.4721], grad_fn=<SqueezeBackward0>)\n",
      "tensor([10.3236, 37.6923, 53.7698, 43.8310], grad_fn=<SqueezeBackward0>)\n",
      "tensor([46.1773, 42.6917, 41.6487, 51.2655], grad_fn=<SqueezeBackward0>)\n",
      "tensor([52.7487, 44.4846, 39.0951, 70.5255], grad_fn=<SqueezeBackward0>)\n",
      "tensor([65.8406, 43.9791, 56.7091, 34.9248], grad_fn=<SqueezeBackward0>)\n",
      "tensor([56.4754, 70.6502, 46.2810, 45.9107], grad_fn=<SqueezeBackward0>)\n",
      "tensor([69.5833, 55.2605, 31.7514, 57.0797], grad_fn=<SqueezeBackward0>)\n",
      "tensor([25.9821, 60.7431, 55.9174, 44.5169], grad_fn=<SqueezeBackward0>)\n",
      "tensor([46.7098, 83.1348, 53.7920, 52.9004], grad_fn=<SqueezeBackward0>)\n",
      "tensor([51.9664, 51.0353, 65.9305, 56.0689], grad_fn=<SqueezeBackward0>)\n",
      "tensor([55.8074, 67.9534, 61.2227, 71.2764], grad_fn=<SqueezeBackward0>)\n",
      "tensor([63.6734, 78.8324, 55.1486, 67.6501], grad_fn=<SqueezeBackward0>)\n",
      "tensor([45.5240, 62.7323, 60.6949, 49.8320], grad_fn=<SqueezeBackward0>)\n",
      "tensor([65.1133, 64.0781, 67.3425, 40.4643], grad_fn=<SqueezeBackward0>)\n",
      "tensor([73.9467, 66.3141, 82.6400, 59.3686], grad_fn=<SqueezeBackward0>)\n",
      "tensor([55.4385, 70.5662, 55.0554, 93.7829], grad_fn=<SqueezeBackward0>)\n",
      "tensor([81.9881, 74.7117, 93.7943, 70.0210], grad_fn=<SqueezeBackward0>)\n",
      "tensor(73.1828, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 1, Loss: 1.6939969156235524e+16\n",
      "tensor([83.9414, 76.7418, 83.4215, 69.4124], grad_fn=<SqueezeBackward0>)\n",
      "tensor([79.5064, 61.2429, 43.8235, 78.5139], grad_fn=<SqueezeBackward0>)\n",
      "tensor([87.2225, 71.9802, 73.1334, 56.0685], grad_fn=<SqueezeBackward0>)\n",
      "tensor([97.8092, 47.9419, 38.9365, 68.5481], grad_fn=<SqueezeBackward0>)\n",
      "tensor([67.0218, 85.0385, 76.9876, 87.4921], grad_fn=<SqueezeBackward0>)\n",
      "tensor([59.5064, 66.2773, 54.1534, 81.2245], grad_fn=<SqueezeBackward0>)\n",
      "tensor([101.9483,  68.8345,  80.9696,  69.3968], grad_fn=<SqueezeBackward0>)\n",
      "tensor([82.6809, 74.8715, 78.7591, 88.0133], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 83.9422,  78.3138,  87.9730, 109.6928], grad_fn=<SqueezeBackward0>)\n",
      "tensor([78.6608, 74.1565, 66.0192, 33.1381], grad_fn=<SqueezeBackward0>)\n",
      "tensor([68.3805, 86.0167, 76.2936, 62.7177], grad_fn=<SqueezeBackward0>)\n",
      "tensor([92.4548, 69.3078, 67.4773, 97.3447], grad_fn=<SqueezeBackward0>)\n",
      "tensor([79.5478, 78.7452, 82.9490, 85.4956], grad_fn=<SqueezeBackward0>)\n",
      "tensor([71.5058, 80.4613, 72.9685, 74.4289], grad_fn=<SqueezeBackward0>)\n",
      "tensor([64.2215, 93.1674, 93.5717, 67.8262], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 88.1588, 103.4187, 112.2246,  88.4394], grad_fn=<SqueezeBackward0>)\n",
      "tensor([86.8391, 98.3819, 85.6446, 79.0651], grad_fn=<SqueezeBackward0>)\n",
      "tensor([92.3960, 73.3553, 83.2828, 98.5881], grad_fn=<SqueezeBackward0>)\n",
      "tensor([95.7611, 78.7039, 90.9089, 84.9408], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 76.5928,  91.2321, 102.7557,  69.7894], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 78.3895,  67.9939,  77.7547, 102.1472], grad_fn=<SqueezeBackward0>)\n",
      "tensor([94.4178, 83.1570, 73.6238, 88.7925], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 85.2979, 102.2154,  81.4374,  83.7951], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 92.9887,  94.6378, 100.6370,  88.7654], grad_fn=<SqueezeBackward0>)\n",
      "tensor([82.0723, 92.9122, 84.2783, 80.5489], grad_fn=<SqueezeBackward0>)\n",
      "tensor([96.9342, 74.0442, 96.5387, 90.5888], grad_fn=<SqueezeBackward0>)\n",
      "tensor([88.1200, 68.7691, 76.1504, 91.4195], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 78.3686, 100.7217,  81.1539,  77.8105], grad_fn=<SqueezeBackward0>)\n",
      "tensor([107.1887,  90.9638,  99.2157,  99.0558], grad_fn=<SqueezeBackward0>)\n",
      "tensor([102.6619,  89.7076,  92.8760,  88.1219], grad_fn=<SqueezeBackward0>)\n",
      "tensor([102.3669,  94.9127,  87.6340, 115.5253], grad_fn=<SqueezeBackward0>)\n",
      "tensor([102.3436,  82.3959,  78.8214,  90.5405], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 83.7641, 110.0337,  94.0234, 101.8552], grad_fn=<SqueezeBackward0>)\n",
      "tensor([132.2363,  93.2541,  96.8621, 104.8299], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 97.9911,  95.7582, 123.0358,  89.9635], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 82.4765,  94.7179, 108.9804, 100.5754], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 80.8367, 115.0843, 105.4300, 116.4554], grad_fn=<SqueezeBackward0>)\n",
      "tensor([116.5587,  77.8220, 103.6813,  94.4336], grad_fn=<SqueezeBackward0>)\n",
      "tensor([100.7988, 106.8948, 100.3955, 101.7206], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 99.3079, 105.0733, 110.2431, 116.4946], grad_fn=<SqueezeBackward0>)\n",
      "tensor([103.1766,  99.7858,  98.1066, 121.1662], grad_fn=<SqueezeBackward0>)\n",
      "tensor([111.7450, 115.9132, 102.5559, 107.0082], grad_fn=<SqueezeBackward0>)\n",
      "tensor([122.0884,  94.7343, 120.1508, 113.5461], grad_fn=<SqueezeBackward0>)\n",
      "tensor([105.2952, 100.5215,  97.9670, 104.1451], grad_fn=<SqueezeBackward0>)\n",
      "tensor([109.0996, 123.9215, 114.0784, 106.6685], grad_fn=<SqueezeBackward0>)\n",
      "tensor([139.6928, 113.7863, 107.7815, 108.5116], grad_fn=<SqueezeBackward0>)\n",
      "tensor([113.2577, 119.6960, 123.1401, 111.0038], grad_fn=<SqueezeBackward0>)\n",
      "tensor([100.3334, 106.0470, 115.1199, 112.7989], grad_fn=<SqueezeBackward0>)\n",
      "tensor([117.0028, 144.3076,  96.0425, 108.5254], grad_fn=<SqueezeBackward0>)\n",
      "tensor([100.7926, 117.5311,  51.1773, 108.4054], grad_fn=<SqueezeBackward0>)\n",
      "tensor([111.8328, 129.2557,  96.4656, 132.6932], grad_fn=<SqueezeBackward0>)\n",
      "tensor([130.4703, 120.6297, 124.5516, 130.3134], grad_fn=<SqueezeBackward0>)\n",
      "tensor([115.7740, 145.1871, 105.5314, 129.0785], grad_fn=<SqueezeBackward0>)\n",
      "tensor([126.1638,  96.3974, 128.2083, 117.5631], grad_fn=<SqueezeBackward0>)\n",
      "tensor([134.4642, 118.3720, 112.7172, 135.2142], grad_fn=<SqueezeBackward0>)\n",
      "tensor([134.9398, 125.6088, 122.4836, 127.3468], grad_fn=<SqueezeBackward0>)\n",
      "tensor([ 91.1191, 164.4377, 117.3995, 118.7612], grad_fn=<SqueezeBackward0>)\n",
      "tensor([124.1868, 128.3659, 123.8948, 132.7841], grad_fn=<SqueezeBackward0>)\n",
      "tensor([112.3721, 122.2762, 115.5450, 127.8925], grad_fn=<SqueezeBackward0>)\n",
      "tensor([119.9050, 123.0474, 138.7185, 126.5234], grad_fn=<SqueezeBackward0>)\n",
      "tensor([146.3856, 127.3119, 125.8322, 121.4551], grad_fn=<SqueezeBackward0>)\n",
      "tensor([123.6347, 123.9674, 120.6922, 141.9658], grad_fn=<SqueezeBackward0>)\n",
      "tensor(131.0443, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 2, Loss: 1.7028114359941608e+16\n",
      "tensor([125.9833, 145.6744, 109.6502, 142.6346], grad_fn=<SqueezeBackward0>)\n",
      "tensor([152.1718, 137.5459, 136.8028, 125.6318], grad_fn=<SqueezeBackward0>)\n",
      "tensor([127.3189, 125.2032, 142.4254, 147.0167], grad_fn=<SqueezeBackward0>)\n",
      "tensor([146.8188, 115.9298, 130.5277, 141.4639], grad_fn=<SqueezeBackward0>)\n",
      "tensor([148.3113, 132.6445, 131.0565, 118.1914], grad_fn=<SqueezeBackward0>)\n",
      "tensor([136.8852, 141.0710, 127.8405, 136.3891], grad_fn=<SqueezeBackward0>)\n",
      "tensor([126.8196, 133.1404, 136.3028, 143.0849], grad_fn=<SqueezeBackward0>)\n",
      "tensor([111.9645, 132.9481, 156.6773, 120.9530], grad_fn=<SqueezeBackward0>)\n",
      "tensor([165.0760, 145.9642, 133.6936, 144.0680], grad_fn=<SqueezeBackward0>)\n",
      "tensor([150.9658, 155.1845, 102.4572, 130.6668], grad_fn=<SqueezeBackward0>)\n",
      "tensor([136.5226, 155.1634, 154.2229, 136.2804], grad_fn=<SqueezeBackward0>)\n",
      "tensor([147.0039, 150.7445, 133.9246, 134.9502], grad_fn=<SqueezeBackward0>)\n",
      "tensor([173.7414, 136.7345, 132.4802, 141.2568], grad_fn=<SqueezeBackward0>)\n",
      "tensor([141.8164, 132.4532, 161.5780, 145.5781], grad_fn=<SqueezeBackward0>)\n",
      "tensor([144.9247, 141.6234, 147.6556, 149.2713], grad_fn=<SqueezeBackward0>)\n",
      "tensor([146.3685, 138.4633, 135.2329, 140.8292], grad_fn=<SqueezeBackward0>)\n",
      "tensor([174.3324, 161.7258, 181.2172, 148.3859], grad_fn=<SqueezeBackward0>)\n",
      "tensor([146.8176, 116.4434, 144.7897, 142.4668], grad_fn=<SqueezeBackward0>)\n",
      "tensor([174.2367, 166.0225, 140.7372, 153.9564], grad_fn=<SqueezeBackward0>)\n",
      "tensor([159.6699, 149.9232, 140.2033, 145.5065], grad_fn=<SqueezeBackward0>)\n",
      "tensor([163.8453, 147.8522, 150.1412, 143.4751], grad_fn=<SqueezeBackward0>)\n",
      "tensor([140.2623, 175.4205, 150.7329, 151.9554], grad_fn=<SqueezeBackward0>)\n",
      "tensor([153.6322, 162.5066, 160.5000, 164.7657], grad_fn=<SqueezeBackward0>)\n",
      "tensor([143.2671, 144.9949, 152.9903, 159.4147], grad_fn=<SqueezeBackward0>)\n",
      "tensor([164.3941, 151.4209, 153.6962, 144.4751], grad_fn=<SqueezeBackward0>)\n",
      "tensor([159.3485, 167.7030, 144.5185, 162.8058], grad_fn=<SqueezeBackward0>)\n",
      "tensor([199.4311, 166.2794, 169.5326, 165.9822], grad_fn=<SqueezeBackward0>)\n",
      "tensor([160.2754, 154.0982,  90.4666, 155.6451], grad_fn=<SqueezeBackward0>)\n",
      "tensor([169.6967, 149.5669, 148.9503, 165.7626], grad_fn=<SqueezeBackward0>)\n",
      "tensor([173.6509, 153.2405, 156.2557, 176.2063], grad_fn=<SqueezeBackward0>)\n",
      "tensor([148.9870, 152.9144, 142.3273, 156.2716], grad_fn=<SqueezeBackward0>)\n",
      "tensor([132.3102, 146.4717, 134.6269, 180.9917], grad_fn=<SqueezeBackward0>)\n",
      "tensor([175.3705, 159.8710, 167.5005, 179.1968], grad_fn=<SqueezeBackward0>)\n",
      "tensor([166.0259, 131.7164, 159.3644, 157.5647], grad_fn=<SqueezeBackward0>)\n",
      "tensor([173.7862, 143.2032, 162.9943, 112.6225], grad_fn=<SqueezeBackward0>)\n",
      "tensor([172.3611, 206.1930, 162.6737, 160.8968], grad_fn=<SqueezeBackward0>)\n",
      "tensor([179.5820, 178.9644, 159.2721, 173.2747], grad_fn=<SqueezeBackward0>)\n",
      "tensor([163.9743, 136.2079, 184.9116, 155.8919], grad_fn=<SqueezeBackward0>)\n",
      "tensor([154.4729, 183.1112, 206.3010, 179.1667], grad_fn=<SqueezeBackward0>)\n",
      "tensor([158.3594, 165.6599, 172.8732, 152.2151], grad_fn=<SqueezeBackward0>)\n",
      "tensor([173.1801, 176.2082, 161.5663, 154.4094], grad_fn=<SqueezeBackward0>)\n",
      "tensor([157.2530, 151.1678, 187.4789, 161.8877], grad_fn=<SqueezeBackward0>)\n",
      "tensor([158.7177, 189.3441, 187.6617, 197.6135], grad_fn=<SqueezeBackward0>)\n",
      "tensor([172.7335, 154.5683, 177.3031, 187.7386], grad_fn=<SqueezeBackward0>)\n",
      "tensor([196.4547, 177.8214, 189.8044, 167.4153], grad_fn=<SqueezeBackward0>)\n",
      "tensor([187.8386, 186.9913, 141.9314, 175.5593], grad_fn=<SqueezeBackward0>)\n",
      "tensor([153.5455, 206.5028, 181.3904, 161.9517], grad_fn=<SqueezeBackward0>)\n",
      "tensor([178.8434, 162.9845, 186.3553, 180.2459], grad_fn=<SqueezeBackward0>)\n",
      "tensor([177.5990, 172.5907, 138.0361, 183.5703], grad_fn=<SqueezeBackward0>)\n",
      "tensor([177.0509, 180.7002, 175.1286, 180.2927], grad_fn=<SqueezeBackward0>)\n",
      "tensor([194.9906, 179.6500, 188.9743, 170.3997], grad_fn=<SqueezeBackward0>)\n",
      "tensor([173.8576, 157.4722, 189.5624, 175.8948], grad_fn=<SqueezeBackward0>)\n",
      "tensor([165.4694, 178.3264, 191.3625, 176.7201], grad_fn=<SqueezeBackward0>)\n",
      "tensor([175.2011, 171.8690, 174.4889, 193.0695], grad_fn=<SqueezeBackward0>)\n",
      "tensor([192.5488, 177.4038, 183.4591, 188.9363], grad_fn=<SqueezeBackward0>)\n",
      "tensor([176.5244, 198.4580, 187.5721, 184.5938], grad_fn=<SqueezeBackward0>)\n",
      "tensor([183.9665, 176.4032, 181.5316, 200.5164], grad_fn=<SqueezeBackward0>)\n",
      "tensor([183.0748, 172.3764, 199.6188, 180.1595], grad_fn=<SqueezeBackward0>)\n",
      "tensor([194.3983, 199.6710, 183.3460, 197.8179], grad_fn=<SqueezeBackward0>)\n",
      "tensor([201.5419, 228.5189, 187.2511, 185.3193], grad_fn=<SqueezeBackward0>)\n",
      "tensor([178.8386, 207.9698, 175.2565, 195.3866], grad_fn=<SqueezeBackward0>)\n",
      "tensor([181.2458, 210.7583, 178.7500, 173.4183], grad_fn=<SqueezeBackward0>)\n",
      "tensor(232.6636, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 3, Loss: 1.6916815116567568e+16\n",
      "tensor([194.0077, 203.0510, 202.8249, 139.6219], grad_fn=<SqueezeBackward0>)\n",
      "tensor([186.7612, 194.4089, 203.7790, 194.5151], grad_fn=<SqueezeBackward0>)\n",
      "tensor([182.8114, 211.2690, 177.9642, 204.1539], grad_fn=<SqueezeBackward0>)\n",
      "tensor([162.0771, 197.4288, 181.7888, 208.4111], grad_fn=<SqueezeBackward0>)\n",
      "tensor([212.6627, 186.1760, 202.1303, 185.1841], grad_fn=<SqueezeBackward0>)\n",
      "tensor([208.3747, 217.4069, 197.8915, 192.0240], grad_fn=<SqueezeBackward0>)\n",
      "tensor([207.8908, 189.0392, 213.1889, 204.9970], grad_fn=<SqueezeBackward0>)\n",
      "tensor([204.3546, 248.2086, 198.4967, 199.2675], grad_fn=<SqueezeBackward0>)\n",
      "tensor([191.0965, 210.8375, 205.0667, 206.5846], grad_fn=<SqueezeBackward0>)\n",
      "tensor([195.3088, 217.1355, 218.9009, 210.5763], grad_fn=<SqueezeBackward0>)\n",
      "tensor([200.4033, 205.4124, 224.3258, 192.2353], grad_fn=<SqueezeBackward0>)\n",
      "tensor([226.5574, 229.1939, 202.1279, 137.4395], grad_fn=<SqueezeBackward0>)\n",
      "tensor([247.5268, 211.9745, 237.0550, 201.7282], grad_fn=<SqueezeBackward0>)\n",
      "tensor([225.0468, 208.5938, 216.3945, 197.1750], grad_fn=<SqueezeBackward0>)\n",
      "tensor([205.2959, 213.1532, 224.6030, 197.9904], grad_fn=<SqueezeBackward0>)\n",
      "tensor([220.9775, 230.7411, 216.7707, 200.7861], grad_fn=<SqueezeBackward0>)\n",
      "tensor([230.9455, 206.7120, 207.7758, 189.2923], grad_fn=<SqueezeBackward0>)\n",
      "tensor([228.1913, 185.8645, 220.1817, 203.1402], grad_fn=<SqueezeBackward0>)\n",
      "tensor([227.3194, 209.7961, 196.9875, 213.9075], grad_fn=<SqueezeBackward0>)\n",
      "tensor([220.6242, 230.6888, 169.3116, 229.7238], grad_fn=<SqueezeBackward0>)\n",
      "tensor([216.5083, 227.1756, 229.3017, 250.5907], grad_fn=<SqueezeBackward0>)\n",
      "tensor([215.6877, 237.5501, 235.1557, 192.6767], grad_fn=<SqueezeBackward0>)\n",
      "tensor([229.9062, 229.1642, 234.8897, 229.6220], grad_fn=<SqueezeBackward0>)\n",
      "tensor([204.7816, 204.4720, 216.9813, 208.4992], grad_fn=<SqueezeBackward0>)\n",
      "tensor([190.3903, 211.1964, 214.8533, 244.3050], grad_fn=<SqueezeBackward0>)\n",
      "tensor([193.1746, 217.1494, 233.5138, 213.0990], grad_fn=<SqueezeBackward0>)\n",
      "tensor([220.0520, 262.9837, 219.9650, 234.0237], grad_fn=<SqueezeBackward0>)\n",
      "tensor([233.5385, 217.7724, 204.1139, 238.1157], grad_fn=<SqueezeBackward0>)\n",
      "tensor([213.0223, 230.9086, 242.6672, 202.5065], grad_fn=<SqueezeBackward0>)\n",
      "tensor([214.5489, 269.5287, 243.0354, 240.7307], grad_fn=<SqueezeBackward0>)\n",
      "tensor([240.5661, 222.1905, 224.4514, 227.1785], grad_fn=<SqueezeBackward0>)\n",
      "tensor([223.7997, 225.0033, 221.8342, 227.9684], grad_fn=<SqueezeBackward0>)\n",
      "tensor([188.3971, 230.8204, 231.5416, 246.0952], grad_fn=<SqueezeBackward0>)\n",
      "tensor([241.1987, 229.3960, 224.0599, 217.8288], grad_fn=<SqueezeBackward0>)\n",
      "tensor([215.8013, 252.7779, 226.9396, 240.8253], grad_fn=<SqueezeBackward0>)\n",
      "tensor([230.0818, 208.7142, 231.8939, 229.1255], grad_fn=<SqueezeBackward0>)\n",
      "tensor([244.5942, 222.8692, 210.4670, 247.0591], grad_fn=<SqueezeBackward0>)\n",
      "tensor([229.4268, 261.3563, 243.2899, 239.1432], grad_fn=<SqueezeBackward0>)\n",
      "tensor([245.9638, 236.7067, 214.9795, 229.5424], grad_fn=<SqueezeBackward0>)\n",
      "tensor([266.9749, 243.7041, 212.7875, 241.6317], grad_fn=<SqueezeBackward0>)\n",
      "tensor([255.3554, 224.0922, 210.5734, 238.3447], grad_fn=<SqueezeBackward0>)\n",
      "tensor([239.7375, 228.6708, 234.4886, 252.2308], grad_fn=<SqueezeBackward0>)\n",
      "tensor([210.0036, 241.4539, 221.4234, 265.8002], grad_fn=<SqueezeBackward0>)\n",
      "tensor([232.1074, 241.9533, 233.0407, 230.3220], grad_fn=<SqueezeBackward0>)\n",
      "tensor([226.8468, 233.6931, 234.3719, 255.7683], grad_fn=<SqueezeBackward0>)\n",
      "tensor([238.6640, 240.9740, 261.6992, 195.7984], grad_fn=<SqueezeBackward0>)\n",
      "tensor([228.3383, 240.2406, 234.5515, 263.5268], grad_fn=<SqueezeBackward0>)\n",
      "tensor([231.7625, 247.4092, 254.6701, 227.8384], grad_fn=<SqueezeBackward0>)\n",
      "tensor([224.7077, 252.9601, 249.3482, 231.5847], grad_fn=<SqueezeBackward0>)\n",
      "tensor([231.7726, 237.6084, 236.2435, 238.9240], grad_fn=<SqueezeBackward0>)\n",
      "tensor([240.5233, 231.4254, 260.7061, 236.8969], grad_fn=<SqueezeBackward0>)\n",
      "tensor([252.9556, 248.1448, 195.8576, 233.2652], grad_fn=<SqueezeBackward0>)\n",
      "tensor([273.7469, 275.3277, 261.0594, 210.2045], grad_fn=<SqueezeBackward0>)\n",
      "tensor([238.4591, 292.4812, 232.2756, 248.2440], grad_fn=<SqueezeBackward0>)\n",
      "tensor([253.0758, 241.2457, 242.0787, 258.0177], grad_fn=<SqueezeBackward0>)\n",
      "tensor([291.8849, 292.3515, 261.3716, 259.3120], grad_fn=<SqueezeBackward0>)\n",
      "tensor([265.4292, 268.2942, 239.7067, 215.1546], grad_fn=<SqueezeBackward0>)\n",
      "tensor([297.4506, 239.7450, 252.4155, 283.7892], grad_fn=<SqueezeBackward0>)\n",
      "tensor([243.7337, 242.3544, 230.9474, 260.1664], grad_fn=<SqueezeBackward0>)\n",
      "tensor([277.0852, 270.8509, 257.1917, 215.9618], grad_fn=<SqueezeBackward0>)\n",
      "tensor([275.2443, 255.4610, 248.4819, 256.8434], grad_fn=<SqueezeBackward0>)\n",
      "tensor([249.1060, 254.2308, 257.6227, 259.5697], grad_fn=<SqueezeBackward0>)\n",
      "tensor(247.5590, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 4, Loss: 1.6931500036772686e+16\n",
      "tensor([253.7003, 263.1252, 244.2093, 246.1805], grad_fn=<SqueezeBackward0>)\n",
      "tensor([260.7733, 259.2043, 235.4368, 267.1595], grad_fn=<SqueezeBackward0>)\n",
      "tensor([284.0060, 251.4505, 302.4114, 270.0256], grad_fn=<SqueezeBackward0>)\n",
      "tensor([255.0136, 249.6800, 259.6784, 261.5650], grad_fn=<SqueezeBackward0>)\n",
      "tensor([270.8223, 242.1215, 238.1395, 266.9085], grad_fn=<SqueezeBackward0>)\n",
      "tensor([309.2323, 270.0701, 241.3861, 292.9993], grad_fn=<SqueezeBackward0>)\n",
      "tensor([286.1565, 267.0774, 239.6319, 248.3846], grad_fn=<SqueezeBackward0>)\n",
      "tensor([248.8143, 271.6577, 236.8916, 255.4382], grad_fn=<SqueezeBackward0>)\n",
      "tensor([271.0134, 311.0539, 254.7501, 242.4655], grad_fn=<SqueezeBackward0>)\n",
      "tensor([277.6698, 267.0893, 263.0051, 271.8309], grad_fn=<SqueezeBackward0>)\n",
      "tensor([283.7708, 260.7254, 282.3689, 245.0567], grad_fn=<SqueezeBackward0>)\n",
      "tensor([254.5460, 261.2956, 268.5242, 267.8967], grad_fn=<SqueezeBackward0>)\n",
      "tensor([270.2178, 294.3846, 267.3511, 232.5071], grad_fn=<SqueezeBackward0>)\n",
      "tensor([258.2831, 238.6567, 257.2301, 282.8654], grad_fn=<SqueezeBackward0>)\n",
      "tensor([301.6703, 289.0369, 270.0246, 256.3230], grad_fn=<SqueezeBackward0>)\n",
      "tensor([264.9002, 217.7800, 302.2451, 265.6667], grad_fn=<SqueezeBackward0>)\n",
      "tensor([268.5458, 285.0011, 282.6387, 294.7870], grad_fn=<SqueezeBackward0>)\n",
      "tensor([267.4470, 278.5551, 273.6320, 255.9801], grad_fn=<SqueezeBackward0>)\n",
      "tensor([277.9755, 310.2646, 296.0216, 257.3969], grad_fn=<SqueezeBackward0>)\n",
      "tensor([303.6378, 266.7953, 283.2854, 293.2764], grad_fn=<SqueezeBackward0>)\n",
      "tensor([296.2955, 293.5153, 246.5570, 260.2401], grad_fn=<SqueezeBackward0>)\n",
      "tensor([285.6748, 287.9010, 278.3893, 297.0383], grad_fn=<SqueezeBackward0>)\n",
      "tensor([326.6023, 271.8940, 274.4163, 273.7085], grad_fn=<SqueezeBackward0>)\n",
      "tensor([293.9579, 268.2744, 272.5839, 283.2661], grad_fn=<SqueezeBackward0>)\n",
      "tensor([290.9235, 299.2444, 283.3124, 292.5692], grad_fn=<SqueezeBackward0>)\n",
      "tensor([277.2417, 219.7616, 301.3969, 297.0389], grad_fn=<SqueezeBackward0>)\n",
      "tensor([274.4955, 284.6260, 287.0406, 291.9555], grad_fn=<SqueezeBackward0>)\n",
      "tensor([308.1649, 273.7578, 279.2827, 284.8406], grad_fn=<SqueezeBackward0>)\n",
      "tensor([272.3937, 281.4321, 304.7025, 286.2339], grad_fn=<SqueezeBackward0>)\n",
      "tensor([292.2583, 285.6725, 302.0610, 306.9546], grad_fn=<SqueezeBackward0>)\n",
      "tensor([285.6843, 304.1107, 293.4391, 275.4942], grad_fn=<SqueezeBackward0>)\n",
      "tensor([282.1487, 295.6199, 286.1310, 295.5683], grad_fn=<SqueezeBackward0>)\n",
      "tensor([304.1238, 275.8276, 286.5575, 316.5931], grad_fn=<SqueezeBackward0>)\n",
      "tensor([294.5283, 269.8381, 234.7451, 279.9321], grad_fn=<SqueezeBackward0>)\n",
      "tensor([309.4559, 262.8226, 275.7079, 304.9982], grad_fn=<SqueezeBackward0>)\n",
      "tensor([295.4012, 305.0670, 246.9267, 295.9147], grad_fn=<SqueezeBackward0>)\n",
      "tensor([342.4509, 278.7780, 282.5345, 262.8421], grad_fn=<SqueezeBackward0>)\n",
      "tensor([307.2906, 310.7024, 289.7196, 308.4391], grad_fn=<SqueezeBackward0>)\n",
      "tensor([292.0014, 277.4272, 295.4476, 317.7627], grad_fn=<SqueezeBackward0>)\n",
      "tensor([295.8086, 328.1242, 292.3832, 290.1131], grad_fn=<SqueezeBackward0>)\n",
      "tensor([312.8433, 311.9269, 256.3694, 301.5569], grad_fn=<SqueezeBackward0>)\n",
      "tensor([317.3900, 301.2698, 352.3339, 292.9931], grad_fn=<SqueezeBackward0>)\n",
      "tensor([294.4232, 316.8301, 323.9107, 288.8414], grad_fn=<SqueezeBackward0>)\n",
      "tensor([321.5650, 318.3983, 316.7871, 278.9025], grad_fn=<SqueezeBackward0>)\n",
      "tensor([318.3766, 303.1115, 290.9955, 279.4273], grad_fn=<SqueezeBackward0>)\n",
      "tensor([316.0657, 322.8728, 319.4632, 320.6120], grad_fn=<SqueezeBackward0>)\n",
      "tensor([303.7118, 327.9251, 311.4501, 312.8647], grad_fn=<SqueezeBackward0>)\n",
      "tensor([320.9922, 321.4957, 290.5984, 298.0001], grad_fn=<SqueezeBackward0>)\n",
      "tensor([310.2082, 356.1578, 276.4861, 323.4058], grad_fn=<SqueezeBackward0>)\n",
      "tensor([309.3388, 292.6823, 325.2138, 294.0574], grad_fn=<SqueezeBackward0>)\n",
      "tensor([308.5322, 350.8440, 325.2479, 257.3627], grad_fn=<SqueezeBackward0>)\n",
      "tensor([319.2778, 308.9757, 342.5394, 328.1754], grad_fn=<SqueezeBackward0>)\n",
      "tensor([291.9683, 315.6855, 303.0885, 262.2671], grad_fn=<SqueezeBackward0>)\n",
      "tensor([361.2804, 319.9589, 292.7435, 292.7861], grad_fn=<SqueezeBackward0>)\n",
      "tensor([333.6535, 281.5457, 321.8784, 315.1643], grad_fn=<SqueezeBackward0>)\n",
      "tensor([351.3643, 321.6732, 310.7091, 340.2829], grad_fn=<SqueezeBackward0>)\n",
      "tensor([321.8032, 319.5880, 311.3551, 304.6301], grad_fn=<SqueezeBackward0>)\n",
      "tensor([338.2716, 318.8792, 241.7391, 308.6487], grad_fn=<SqueezeBackward0>)\n",
      "tensor([325.1887, 345.0528, 287.6443, 342.7120], grad_fn=<SqueezeBackward0>)\n",
      "tensor([328.4664, 271.1984, 328.9197, 302.4361], grad_fn=<SqueezeBackward0>)\n",
      "tensor([343.7087, 304.5346, 359.0364, 318.3546], grad_fn=<SqueezeBackward0>)\n",
      "tensor([345.2753, 324.1610, 277.7510, 321.2307], grad_fn=<SqueezeBackward0>)\n",
      "tensor(323.4479, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 5, Loss: 1.692465533636309e+16\n",
      "tensor([305.1568, 323.1605, 301.9666, 305.7683], grad_fn=<SqueezeBackward0>)\n",
      "tensor([319.7446, 345.2775, 324.5778, 332.5713], grad_fn=<SqueezeBackward0>)\n",
      "tensor([328.5597, 314.6244, 276.7234, 301.0421], grad_fn=<SqueezeBackward0>)\n",
      "tensor([320.6397, 328.9343, 330.5746, 308.5200], grad_fn=<SqueezeBackward0>)\n",
      "tensor([332.2086, 301.4189, 333.1912, 319.6148], grad_fn=<SqueezeBackward0>)\n",
      "tensor([311.1310, 304.2321, 351.0287, 340.3867], grad_fn=<SqueezeBackward0>)\n",
      "tensor([341.3060, 347.0580, 317.1958, 378.1314], grad_fn=<SqueezeBackward0>)\n",
      "tensor([303.2359, 338.0475, 355.5184, 309.7308], grad_fn=<SqueezeBackward0>)\n",
      "tensor([299.6631, 358.3431, 328.0705, 343.1246], grad_fn=<SqueezeBackward0>)\n",
      "tensor([336.5877, 355.0918, 332.8409, 323.7433], grad_fn=<SqueezeBackward0>)\n",
      "tensor([364.7218, 300.3971, 349.4309, 340.1103], grad_fn=<SqueezeBackward0>)\n",
      "tensor([349.7502, 303.0984, 352.1626, 360.1919], grad_fn=<SqueezeBackward0>)\n",
      "tensor([321.8692, 347.6876, 321.6244, 315.3580], grad_fn=<SqueezeBackward0>)\n",
      "tensor([283.2108, 308.0522, 340.5690, 285.0220], grad_fn=<SqueezeBackward0>)\n",
      "tensor([328.3576, 334.8774, 354.3804, 334.4564], grad_fn=<SqueezeBackward0>)\n",
      "tensor([359.1924, 303.6261, 362.7990, 343.2405], grad_fn=<SqueezeBackward0>)\n",
      "tensor([324.1124, 331.2219, 333.0836, 357.4176], grad_fn=<SqueezeBackward0>)\n",
      "tensor([346.3008, 269.5450, 391.2575, 359.8239], grad_fn=<SqueezeBackward0>)\n",
      "tensor([296.6451, 332.9716, 374.3272, 343.0664], grad_fn=<SqueezeBackward0>)\n",
      "tensor([350.4684, 336.5271, 340.3179, 328.3300], grad_fn=<SqueezeBackward0>)\n",
      "tensor([315.4197, 333.3405, 360.4449, 332.4965], grad_fn=<SqueezeBackward0>)\n",
      "tensor([348.4466, 325.5409, 352.6081, 338.3906], grad_fn=<SqueezeBackward0>)\n",
      "tensor([280.0564, 339.0900, 363.6482, 363.4726], grad_fn=<SqueezeBackward0>)\n",
      "tensor([314.3050, 340.1137, 335.0492, 347.0058], grad_fn=<SqueezeBackward0>)\n",
      "tensor([347.3836, 321.9437, 356.0815, 349.3757], grad_fn=<SqueezeBackward0>)\n",
      "tensor([347.7077, 355.9135, 336.0916, 373.3991], grad_fn=<SqueezeBackward0>)\n",
      "tensor([364.2895, 369.0985, 361.6285, 363.1419], grad_fn=<SqueezeBackward0>)\n",
      "tensor([336.6857, 351.2409, 370.3268, 369.0127], grad_fn=<SqueezeBackward0>)\n",
      "tensor([352.8352, 366.3889, 368.1920, 377.0122], grad_fn=<SqueezeBackward0>)\n",
      "tensor([322.6712, 369.5144, 347.4242, 354.0369], grad_fn=<SqueezeBackward0>)\n",
      "tensor([337.3796, 337.9862, 376.6164, 350.5136], grad_fn=<SqueezeBackward0>)\n",
      "tensor([318.5563, 331.2341, 341.7602, 355.0893], grad_fn=<SqueezeBackward0>)\n",
      "tensor([358.5218, 401.6560, 374.5715, 358.2783], grad_fn=<SqueezeBackward0>)\n",
      "tensor([350.2232, 353.0870, 374.4441, 396.2503], grad_fn=<SqueezeBackward0>)\n",
      "tensor([366.3161, 382.8023, 363.1472, 351.9421], grad_fn=<SqueezeBackward0>)\n",
      "tensor([358.2213, 388.6502, 378.9301, 351.7190], grad_fn=<SqueezeBackward0>)\n",
      "tensor([334.8602, 364.7322, 361.0645, 369.1649], grad_fn=<SqueezeBackward0>)\n",
      "tensor([390.0503, 354.7870, 358.8146, 356.2602], grad_fn=<SqueezeBackward0>)\n",
      "tensor([407.4241, 363.1891, 359.4147, 365.9921], grad_fn=<SqueezeBackward0>)\n",
      "tensor([387.5006, 360.6043, 346.0827, 374.4261], grad_fn=<SqueezeBackward0>)\n",
      "tensor([348.9290, 344.5757, 368.3799, 379.3500], grad_fn=<SqueezeBackward0>)\n",
      "tensor([339.5952, 379.9962, 358.4319, 416.7585], grad_fn=<SqueezeBackward0>)\n",
      "tensor([417.0603, 374.3982, 353.7934, 355.3742], grad_fn=<SqueezeBackward0>)\n",
      "tensor([353.0021, 379.4799, 340.4978, 390.0934], grad_fn=<SqueezeBackward0>)\n",
      "tensor([422.4866, 367.4277, 383.2173, 289.0747], grad_fn=<SqueezeBackward0>)\n",
      "tensor([380.3364, 320.5588, 398.8707, 358.4496], grad_fn=<SqueezeBackward0>)\n",
      "tensor([383.1182, 384.6042, 387.1515, 313.1496], grad_fn=<SqueezeBackward0>)\n",
      "tensor([357.1361, 388.6665, 379.4268, 371.5965], grad_fn=<SqueezeBackward0>)\n",
      "tensor([388.8130, 395.9682, 402.2233, 369.9925], grad_fn=<SqueezeBackward0>)\n",
      "tensor([369.3721, 332.3799, 349.6175, 373.1235], grad_fn=<SqueezeBackward0>)\n",
      "tensor([383.8857, 328.0998, 329.1474, 347.1042], grad_fn=<SqueezeBackward0>)\n",
      "tensor([418.9880, 392.2668, 391.6497, 373.3259], grad_fn=<SqueezeBackward0>)\n",
      "tensor([321.1920, 365.4187, 379.5204, 378.2702], grad_fn=<SqueezeBackward0>)\n",
      "tensor([363.7124, 416.8596, 408.4431, 378.3568], grad_fn=<SqueezeBackward0>)\n",
      "tensor([401.5100, 439.1222, 384.8997, 364.6923], grad_fn=<SqueezeBackward0>)\n",
      "tensor([389.9137, 334.6416, 362.4532, 359.7482], grad_fn=<SqueezeBackward0>)\n",
      "tensor([405.2967, 370.4191, 388.7126, 393.9657], grad_fn=<SqueezeBackward0>)\n",
      "tensor([355.9563, 376.6132, 358.7438, 412.7794], grad_fn=<SqueezeBackward0>)\n",
      "tensor([366.6125, 345.3369, 366.6815, 362.9368], grad_fn=<SqueezeBackward0>)\n",
      "tensor([391.5930, 304.7061, 394.4137, 385.2738], grad_fn=<SqueezeBackward0>)\n",
      "tensor([394.1874, 442.9770, 402.5528, 362.0423], grad_fn=<SqueezeBackward0>)\n",
      "tensor([398.1810, 371.3442, 430.4209, 399.1616], grad_fn=<SqueezeBackward0>)\n",
      "tensor(407.5568, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 6, Loss: 1.7697834830226838e+16\n",
      "tensor([412.0157, 392.4949, 355.3966, 360.4590], grad_fn=<SqueezeBackward0>)\n",
      "tensor([435.0075, 378.5553, 404.8250, 317.1215], grad_fn=<SqueezeBackward0>)\n",
      "tensor([391.9437, 368.3992, 361.7902, 384.9209], grad_fn=<SqueezeBackward0>)\n",
      "tensor([360.0760, 404.8608, 372.0106, 418.8032], grad_fn=<SqueezeBackward0>)\n",
      "tensor([353.8707, 383.7780, 423.9646, 385.6833], grad_fn=<SqueezeBackward0>)\n",
      "tensor([417.9890, 452.2159, 401.8495, 383.5016], grad_fn=<SqueezeBackward0>)\n",
      "tensor([372.5421, 396.1587, 370.0795, 383.4392], grad_fn=<SqueezeBackward0>)\n",
      "tensor([347.0549, 409.8343, 337.6555, 378.3339], grad_fn=<SqueezeBackward0>)\n",
      "tensor([393.5261, 438.2491, 419.4949, 388.7353], grad_fn=<SqueezeBackward0>)\n",
      "tensor([383.9612, 414.0841, 416.3811, 410.1996], grad_fn=<SqueezeBackward0>)\n",
      "tensor([407.2353, 388.2584, 387.7424, 383.6981], grad_fn=<SqueezeBackward0>)\n",
      "tensor([404.3153, 372.2065, 420.0951, 420.5222], grad_fn=<SqueezeBackward0>)\n",
      "tensor([419.9671, 341.1147, 397.9752, 399.0080], grad_fn=<SqueezeBackward0>)\n",
      "tensor([412.5775, 392.1837, 393.9872, 386.7307], grad_fn=<SqueezeBackward0>)\n",
      "tensor([404.5299, 389.0162, 436.5057, 384.8603], grad_fn=<SqueezeBackward0>)\n",
      "tensor([379.9518, 401.3147, 415.2484, 378.4564], grad_fn=<SqueezeBackward0>)\n",
      "tensor([392.0269, 434.1711, 354.2299, 414.6643], grad_fn=<SqueezeBackward0>)\n",
      "tensor([378.2953, 416.1390, 406.3315, 422.2459], grad_fn=<SqueezeBackward0>)\n",
      "tensor([452.5765, 346.2274, 425.6805, 402.1254], grad_fn=<SqueezeBackward0>)\n",
      "tensor([429.4927, 385.8882, 462.8905, 327.5320], grad_fn=<SqueezeBackward0>)\n",
      "tensor([440.9851, 396.1391, 411.1346, 412.1288], grad_fn=<SqueezeBackward0>)\n",
      "tensor([432.9674, 407.5587, 408.9501, 359.0292], grad_fn=<SqueezeBackward0>)\n",
      "tensor([424.9985, 437.3602, 379.5853, 414.4706], grad_fn=<SqueezeBackward0>)\n",
      "tensor([432.7313, 440.0228, 390.7078, 433.3526], grad_fn=<SqueezeBackward0>)\n",
      "tensor([420.1445, 416.2183, 435.1510, 333.6243], grad_fn=<SqueezeBackward0>)\n",
      "tensor([404.0215, 353.0995, 432.5813, 420.0355], grad_fn=<SqueezeBackward0>)\n",
      "tensor([449.5546, 388.0875, 366.1271, 425.1675], grad_fn=<SqueezeBackward0>)\n",
      "tensor([410.6962, 437.4853, 405.8928, 476.2340], grad_fn=<SqueezeBackward0>)\n",
      "tensor([436.2932, 388.0979, 406.4572, 428.1531], grad_fn=<SqueezeBackward0>)\n",
      "tensor([418.3031, 432.8543, 412.3422, 356.9410], grad_fn=<SqueezeBackward0>)\n",
      "tensor([404.8292, 387.3045, 417.9732, 431.0377], grad_fn=<SqueezeBackward0>)\n",
      "tensor([427.6505, 379.2638, 439.9073, 395.1615], grad_fn=<SqueezeBackward0>)\n",
      "tensor([415.9379, 386.4987, 439.8920, 407.8755], grad_fn=<SqueezeBackward0>)\n",
      "tensor([444.0297, 446.9691, 440.1500, 401.8508], grad_fn=<SqueezeBackward0>)\n",
      "tensor([382.4449, 388.0105, 462.4764, 423.9963], grad_fn=<SqueezeBackward0>)\n",
      "tensor([417.8058, 382.5593, 403.0962, 449.7558], grad_fn=<SqueezeBackward0>)\n",
      "tensor([446.1005, 424.3326, 431.9101, 390.5370], grad_fn=<SqueezeBackward0>)\n",
      "tensor([419.5396, 461.1339, 411.9796, 455.2841], grad_fn=<SqueezeBackward0>)\n",
      "tensor([415.2940, 477.5988, 408.4134, 420.2503], grad_fn=<SqueezeBackward0>)\n",
      "tensor([441.8734, 442.4912, 438.5258, 434.5735], grad_fn=<SqueezeBackward0>)\n",
      "tensor([442.5607, 411.4033, 399.1198, 432.0554], grad_fn=<SqueezeBackward0>)\n",
      "tensor([445.7030, 438.5720, 422.8494, 409.9590], grad_fn=<SqueezeBackward0>)\n",
      "tensor([450.1756, 463.4527, 462.1830, 431.0993], grad_fn=<SqueezeBackward0>)\n",
      "tensor([425.2727, 409.9762, 427.2635, 461.6393], grad_fn=<SqueezeBackward0>)\n",
      "tensor([435.0808, 438.4496, 446.1532, 417.7521], grad_fn=<SqueezeBackward0>)\n",
      "tensor([464.3178, 434.3875, 416.2838, 487.8066], grad_fn=<SqueezeBackward0>)\n",
      "tensor([447.1679, 436.6351, 429.1524, 491.9985], grad_fn=<SqueezeBackward0>)\n",
      "tensor([438.5135, 420.6039, 407.4406, 418.7610], grad_fn=<SqueezeBackward0>)\n",
      "tensor([425.0096, 449.2355, 467.5818, 459.2796], grad_fn=<SqueezeBackward0>)\n",
      "tensor([447.2138, 453.6199, 447.0415, 404.2274], grad_fn=<SqueezeBackward0>)\n",
      "tensor([450.6198, 488.1281, 470.5970, 421.2185], grad_fn=<SqueezeBackward0>)\n",
      "tensor([458.8728, 444.0102, 449.3928, 458.3152], grad_fn=<SqueezeBackward0>)\n",
      "tensor([513.4760, 482.9067, 452.9514, 435.5195], grad_fn=<SqueezeBackward0>)\n",
      "tensor([453.5024, 458.0232, 446.2555, 443.0890], grad_fn=<SqueezeBackward0>)\n",
      "tensor([428.0996, 441.4683, 440.7935, 457.4978], grad_fn=<SqueezeBackward0>)\n",
      "tensor([502.1483, 403.2021, 463.7393, 467.7490], grad_fn=<SqueezeBackward0>)\n",
      "tensor([453.3033, 354.7654, 463.9414, 440.8531], grad_fn=<SqueezeBackward0>)\n",
      "tensor([443.8762, 456.2978, 462.3976, 447.5981], grad_fn=<SqueezeBackward0>)\n",
      "tensor([467.9647, 419.4915, 429.1584, 452.9471], grad_fn=<SqueezeBackward0>)\n",
      "tensor([445.3901, 480.3407, 479.1133, 398.2385], grad_fn=<SqueezeBackward0>)\n",
      "tensor([423.2590, 468.7134, 472.8961, 395.9263], grad_fn=<SqueezeBackward0>)\n",
      "tensor([397.5421, 466.8416, 469.5153, 479.9293], grad_fn=<SqueezeBackward0>)\n",
      "tensor(513.4606, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 7, Loss: 1.6916766155591484e+16\n",
      "tensor([455.9446, 427.2293, 410.1681, 452.8937], grad_fn=<SqueezeBackward0>)\n",
      "tensor([454.1741, 454.3853, 447.4611, 457.6129], grad_fn=<SqueezeBackward0>)\n",
      "tensor([481.3714, 506.4779, 440.7112, 477.9664], grad_fn=<SqueezeBackward0>)\n",
      "tensor([436.7693, 429.0082, 464.9271, 445.8667], grad_fn=<SqueezeBackward0>)\n",
      "tensor([479.6001, 437.5881, 520.9365, 427.9450], grad_fn=<SqueezeBackward0>)\n",
      "tensor([476.1385, 469.1051, 451.4634, 447.2527], grad_fn=<SqueezeBackward0>)\n",
      "tensor([440.3634, 459.6393, 438.5320, 473.5089], grad_fn=<SqueezeBackward0>)\n",
      "tensor([466.4746, 491.8052, 471.0705, 478.0180], grad_fn=<SqueezeBackward0>)\n",
      "tensor([462.3044, 459.5524, 470.1857, 479.8302], grad_fn=<SqueezeBackward0>)\n",
      "tensor([476.4244, 469.1258, 435.0701, 367.3919], grad_fn=<SqueezeBackward0>)\n",
      "tensor([452.4998, 484.9807, 457.3991, 423.1552], grad_fn=<SqueezeBackward0>)\n",
      "tensor([469.7495, 496.4894, 524.6108, 477.4820], grad_fn=<SqueezeBackward0>)\n",
      "tensor([460.2307, 477.3156, 460.7203, 455.3700], grad_fn=<SqueezeBackward0>)\n",
      "tensor([405.0873, 518.7598, 498.2423, 498.8572], grad_fn=<SqueezeBackward0>)\n",
      "tensor([490.6315, 460.2676, 441.2446, 441.0501], grad_fn=<SqueezeBackward0>)\n",
      "tensor([401.6886, 439.7155, 526.5458, 491.3652], grad_fn=<SqueezeBackward0>)\n",
      "tensor([444.5692, 400.2357, 463.1355, 402.4216], grad_fn=<SqueezeBackward0>)\n",
      "tensor([476.7102, 475.5429, 456.7999, 485.7290], grad_fn=<SqueezeBackward0>)\n",
      "tensor([442.7038, 477.7598, 505.0127, 487.2319], grad_fn=<SqueezeBackward0>)\n",
      "tensor([453.1453, 485.7484, 489.3200, 503.5567], grad_fn=<SqueezeBackward0>)\n",
      "tensor([470.2907, 414.9611, 492.8599, 498.0568], grad_fn=<SqueezeBackward0>)\n",
      "tensor([487.0516, 492.0906, 536.9428, 493.8344], grad_fn=<SqueezeBackward0>)\n",
      "tensor([459.6636, 487.9053, 474.6343, 532.0483], grad_fn=<SqueezeBackward0>)\n",
      "tensor([496.6424, 441.6951, 501.4182, 462.7063], grad_fn=<SqueezeBackward0>)\n",
      "tensor([517.8920, 467.8174, 468.6799, 522.2516], grad_fn=<SqueezeBackward0>)\n",
      "tensor([478.4925, 463.7254, 412.0146, 468.8000], grad_fn=<SqueezeBackward0>)\n",
      "tensor([497.6714, 447.3088, 457.5836, 508.8116], grad_fn=<SqueezeBackward0>)\n",
      "tensor([511.7778, 505.0178, 424.5196, 512.4430], grad_fn=<SqueezeBackward0>)\n",
      "tensor([465.2010, 465.4529, 482.7791, 476.0845], grad_fn=<SqueezeBackward0>)\n",
      "tensor([481.2770, 445.3693, 508.5610, 426.0256], grad_fn=<SqueezeBackward0>)\n",
      "tensor([483.3344, 449.1435, 490.0898, 456.1923], grad_fn=<SqueezeBackward0>)\n",
      "tensor([511.7144, 487.9690, 508.8276, 498.1432], grad_fn=<SqueezeBackward0>)\n",
      "tensor([505.0636, 477.0752, 464.2661, 477.5956], grad_fn=<SqueezeBackward0>)\n",
      "tensor([466.2701, 508.0375, 424.0812, 445.1000], grad_fn=<SqueezeBackward0>)\n",
      "tensor([429.4952, 501.9720, 472.2131, 465.2549], grad_fn=<SqueezeBackward0>)\n",
      "tensor([497.4028, 501.5845, 556.8570, 491.2428], grad_fn=<SqueezeBackward0>)\n",
      "tensor([483.8039, 469.6376, 439.8811, 482.1830], grad_fn=<SqueezeBackward0>)\n",
      "tensor([495.3097, 479.1847, 473.3866, 518.5599], grad_fn=<SqueezeBackward0>)\n",
      "tensor([501.5061, 523.3657, 569.0186, 511.3184], grad_fn=<SqueezeBackward0>)\n",
      "tensor([494.1393, 477.2680, 451.6458, 514.6072], grad_fn=<SqueezeBackward0>)\n",
      "tensor([469.9108, 513.6237, 513.6050, 536.6194], grad_fn=<SqueezeBackward0>)\n",
      "tensor([527.6813, 503.5942, 493.1072, 422.6394], grad_fn=<SqueezeBackward0>)\n",
      "tensor([489.3141, 486.5824, 490.7242, 547.3797], grad_fn=<SqueezeBackward0>)\n",
      "tensor([456.2192, 524.5795, 448.8489, 492.7789], grad_fn=<SqueezeBackward0>)\n",
      "tensor([507.3616, 477.4138, 510.7845, 485.2802], grad_fn=<SqueezeBackward0>)\n",
      "tensor([520.5077, 509.2261, 501.0211, 503.4898], grad_fn=<SqueezeBackward0>)\n",
      "tensor([540.9310, 557.9703, 508.0219, 501.9100], grad_fn=<SqueezeBackward0>)\n",
      "tensor([513.2825, 485.7968, 463.7417, 516.9626], grad_fn=<SqueezeBackward0>)\n",
      "tensor([509.3393, 536.1542, 474.2959, 521.7914], grad_fn=<SqueezeBackward0>)\n",
      "tensor([496.3076, 512.0828, 535.9882, 412.5969], grad_fn=<SqueezeBackward0>)\n",
      "tensor([468.5632, 542.5236, 529.3056, 563.2731], grad_fn=<SqueezeBackward0>)\n",
      "tensor([414.6929, 492.3502, 493.7199, 512.7440], grad_fn=<SqueezeBackward0>)\n",
      "tensor([522.1322, 558.1819, 472.6974, 458.2552], grad_fn=<SqueezeBackward0>)\n",
      "tensor([540.1828, 458.0154, 488.8307, 499.6279], grad_fn=<SqueezeBackward0>)\n",
      "tensor([527.5076, 517.8471, 517.6393, 523.7800], grad_fn=<SqueezeBackward0>)\n",
      "tensor([536.2664, 530.2136, 423.2898, 447.8858], grad_fn=<SqueezeBackward0>)\n",
      "tensor([527.1844, 539.9210, 484.6225, 483.4101], grad_fn=<SqueezeBackward0>)\n",
      "tensor([525.5900, 473.3123, 475.3841, 534.6341], grad_fn=<SqueezeBackward0>)\n",
      "tensor([501.4207, 529.2913, 521.7234, 545.5532], grad_fn=<SqueezeBackward0>)\n",
      "tensor([520.0132, 547.4390, 513.9763, 461.8319], grad_fn=<SqueezeBackward0>)\n",
      "tensor([531.9034, 474.0094, 510.8831, 507.5456], grad_fn=<SqueezeBackward0>)\n",
      "tensor([506.3720, 546.1344, 529.2260, 478.7275], grad_fn=<SqueezeBackward0>)\n",
      "tensor(505.4433, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 8, Loss: 1.6973232586092478e+16\n",
      "tensor([521.2347, 552.2045, 539.9881, 468.4240], grad_fn=<SqueezeBackward0>)\n",
      "tensor([488.1869, 553.8249, 543.7314, 503.0718], grad_fn=<SqueezeBackward0>)\n",
      "tensor([555.1026, 539.4931, 553.5822, 574.1194], grad_fn=<SqueezeBackward0>)\n",
      "tensor([530.6332, 470.2646, 511.7294, 506.6460], grad_fn=<SqueezeBackward0>)\n",
      "tensor([528.9725, 451.1274, 550.2319, 518.0602], grad_fn=<SqueezeBackward0>)\n",
      "tensor([448.8987, 447.3605, 517.5925, 516.9725], grad_fn=<SqueezeBackward0>)\n",
      "tensor([549.3687, 486.6107, 532.5595, 533.7917], grad_fn=<SqueezeBackward0>)\n",
      "tensor([547.1404, 552.2161, 454.9595, 588.8356], grad_fn=<SqueezeBackward0>)\n",
      "tensor([452.5495, 503.1235, 489.9987, 537.0092], grad_fn=<SqueezeBackward0>)\n",
      "tensor([491.1345, 525.6003, 500.8718, 518.2762], grad_fn=<SqueezeBackward0>)\n",
      "tensor([493.5122, 523.3863, 549.5762, 521.2218], grad_fn=<SqueezeBackward0>)\n",
      "tensor([476.8094, 499.4887, 475.8863, 561.3342], grad_fn=<SqueezeBackward0>)\n",
      "tensor([456.4046, 544.0562, 536.6367, 538.8543], grad_fn=<SqueezeBackward0>)\n",
      "tensor([558.1295, 560.2209, 470.3225, 520.4219], grad_fn=<SqueezeBackward0>)\n",
      "tensor([545.4410, 557.2758, 568.6796, 526.0278], grad_fn=<SqueezeBackward0>)\n",
      "tensor([579.2579, 482.4462, 533.4800, 565.7223], grad_fn=<SqueezeBackward0>)\n",
      "tensor([517.8941, 560.0905, 533.7548, 496.4762], grad_fn=<SqueezeBackward0>)\n",
      "tensor([546.9759, 546.8343, 505.0584, 539.7762], grad_fn=<SqueezeBackward0>)\n",
      "tensor([529.0341, 550.4607, 528.7803, 558.7047], grad_fn=<SqueezeBackward0>)\n",
      "tensor([515.1022, 599.8527, 498.0352, 535.0812], grad_fn=<SqueezeBackward0>)\n",
      "tensor([529.9709, 510.3382, 498.2083, 562.8716], grad_fn=<SqueezeBackward0>)\n",
      "tensor([528.7845, 558.6072, 529.7938, 522.8449], grad_fn=<SqueezeBackward0>)\n",
      "tensor([540.4099, 552.0541, 545.0698, 573.9568], grad_fn=<SqueezeBackward0>)\n",
      "tensor([559.4084, 555.1076, 576.9868, 529.7245], grad_fn=<SqueezeBackward0>)\n",
      "tensor([449.2408, 517.8290, 560.9550, 579.5622], grad_fn=<SqueezeBackward0>)\n",
      "tensor([547.1967, 532.5294, 528.4753, 532.8659], grad_fn=<SqueezeBackward0>)\n",
      "tensor([511.6702, 495.5195, 533.6042, 592.1191], grad_fn=<SqueezeBackward0>)\n",
      "tensor([566.0058, 570.0067, 479.8564, 561.6184], grad_fn=<SqueezeBackward0>)\n",
      "tensor([557.2412, 563.8773, 614.6219, 610.3237], grad_fn=<SqueezeBackward0>)\n",
      "tensor([514.7014, 568.0845, 565.2906, 541.9577], grad_fn=<SqueezeBackward0>)\n",
      "tensor([536.9748, 585.9059, 606.1203, 577.0340], grad_fn=<SqueezeBackward0>)\n",
      "tensor([463.0055, 608.5192, 543.4046, 585.5437], grad_fn=<SqueezeBackward0>)\n",
      "tensor([571.7958, 529.1236, 535.0757, 559.5250], grad_fn=<SqueezeBackward0>)\n",
      "tensor([579.9600, 548.9990, 438.4202, 512.5532], grad_fn=<SqueezeBackward0>)\n",
      "tensor([589.1286, 568.3201, 570.0258, 525.9747], grad_fn=<SqueezeBackward0>)\n",
      "tensor([536.3358, 550.0049, 536.6651, 545.1482], grad_fn=<SqueezeBackward0>)\n",
      "tensor([505.0562, 567.2084, 554.6660, 556.2332], grad_fn=<SqueezeBackward0>)\n",
      "tensor([532.4505, 528.1553, 523.9695, 580.4101], grad_fn=<SqueezeBackward0>)\n",
      "tensor([515.9899, 549.6833, 592.2371, 626.8918], grad_fn=<SqueezeBackward0>)\n",
      "tensor([561.7830, 523.2823, 581.7880, 569.3707], grad_fn=<SqueezeBackward0>)\n",
      "tensor([564.0303, 570.6190, 537.4681, 545.1047], grad_fn=<SqueezeBackward0>)\n",
      "tensor([552.0068, 569.4562, 526.2014, 543.5991], grad_fn=<SqueezeBackward0>)\n",
      "tensor([575.2057, 585.9379, 565.9590, 569.1075], grad_fn=<SqueezeBackward0>)\n",
      "tensor([551.9408, 591.6644, 581.1528, 576.5040], grad_fn=<SqueezeBackward0>)\n",
      "tensor([528.3253, 542.5287, 589.1167, 580.5439], grad_fn=<SqueezeBackward0>)\n",
      "tensor([600.3078, 589.0480, 552.8489, 582.8986], grad_fn=<SqueezeBackward0>)\n",
      "tensor([592.7177, 500.8031, 567.7026, 613.8083], grad_fn=<SqueezeBackward0>)\n",
      "tensor([584.4753, 558.3511, 587.3785, 576.3475], grad_fn=<SqueezeBackward0>)\n",
      "tensor([584.4031, 548.0892, 601.3769, 591.7198], grad_fn=<SqueezeBackward0>)\n",
      "tensor([537.3177, 564.2485, 597.1174, 577.0202], grad_fn=<SqueezeBackward0>)\n",
      "tensor([520.3839, 550.8326, 470.6009, 561.2595], grad_fn=<SqueezeBackward0>)\n",
      "tensor([587.3797, 592.2841, 604.7200, 608.4766], grad_fn=<SqueezeBackward0>)\n",
      "tensor([584.3482, 595.5397, 591.3040, 508.0771], grad_fn=<SqueezeBackward0>)\n",
      "tensor([583.3845, 607.9124, 635.7799, 584.9399], grad_fn=<SqueezeBackward0>)\n",
      "tensor([664.1469, 547.3640, 501.3636, 556.4525], grad_fn=<SqueezeBackward0>)\n",
      "tensor([560.4680, 585.7576, 561.0528, 595.5592], grad_fn=<SqueezeBackward0>)\n",
      "tensor([530.2037, 526.3646, 632.8956, 588.1971], grad_fn=<SqueezeBackward0>)\n",
      "tensor([552.3117, 577.2548, 489.8167, 630.5840], grad_fn=<SqueezeBackward0>)\n",
      "tensor([568.7542, 566.9139, 622.3261, 607.7042], grad_fn=<SqueezeBackward0>)\n",
      "tensor([540.3347, 590.7990, 587.4437, 647.0919], grad_fn=<SqueezeBackward0>)\n",
      "tensor([657.6436, 535.1942, 579.1662, 551.6764], grad_fn=<SqueezeBackward0>)\n",
      "tensor([585.9124, 578.3586, 621.6616, 586.8776], grad_fn=<SqueezeBackward0>)\n",
      "tensor(553.3792, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 9, Loss: 1.7094690682083946e+16\n",
      "tensor([610.8692, 595.3587, 611.0739, 560.6370], grad_fn=<SqueezeBackward0>)\n",
      "tensor([574.4915, 605.1407, 571.9902, 572.9926], grad_fn=<SqueezeBackward0>)\n",
      "tensor([581.0242, 563.8096, 575.2935, 592.6418], grad_fn=<SqueezeBackward0>)\n",
      "tensor([597.3127, 551.0406, 595.2895, 602.8696], grad_fn=<SqueezeBackward0>)\n",
      "tensor([598.8523, 608.0931, 556.7717, 604.7633], grad_fn=<SqueezeBackward0>)\n",
      "tensor([522.5973, 606.5441, 613.6804, 600.9987], grad_fn=<SqueezeBackward0>)\n",
      "tensor([653.9988, 575.1290, 535.7004, 597.2288], grad_fn=<SqueezeBackward0>)\n",
      "tensor([600.1465, 522.7252, 512.8387, 546.8203], grad_fn=<SqueezeBackward0>)\n",
      "tensor([601.6558, 616.2874, 544.2783, 603.7191], grad_fn=<SqueezeBackward0>)\n",
      "tensor([551.2010, 553.3638, 630.4265, 540.7805], grad_fn=<SqueezeBackward0>)\n",
      "tensor([554.1011, 619.0046, 531.8156, 614.4436], grad_fn=<SqueezeBackward0>)\n",
      "tensor([587.8002, 624.0828, 629.0153, 538.5834], grad_fn=<SqueezeBackward0>)\n",
      "tensor([563.2257, 577.8995, 628.0081, 582.3725], grad_fn=<SqueezeBackward0>)\n",
      "tensor([607.7086, 600.0860, 514.5114, 555.2384], grad_fn=<SqueezeBackward0>)\n",
      "tensor([631.8270, 552.2881, 628.1938, 560.7027], grad_fn=<SqueezeBackward0>)\n",
      "tensor([545.8188, 580.2361, 609.4634, 598.1123], grad_fn=<SqueezeBackward0>)\n",
      "tensor([605.5724, 624.3663, 496.1078, 671.7103], grad_fn=<SqueezeBackward0>)\n",
      "tensor([610.8558, 614.7647, 592.0625, 515.9131], grad_fn=<SqueezeBackward0>)\n",
      "tensor([573.3405, 576.6302, 612.8994, 592.8011], grad_fn=<SqueezeBackward0>)\n",
      "tensor([615.4769, 642.1938, 629.7036, 607.0187], grad_fn=<SqueezeBackward0>)\n",
      "tensor([640.8295, 632.0193, 667.4296, 642.3243], grad_fn=<SqueezeBackward0>)\n",
      "tensor([577.6464, 602.3601, 635.1757, 624.0776], grad_fn=<SqueezeBackward0>)\n",
      "tensor([522.6273, 621.7172, 663.0150, 627.3793], grad_fn=<SqueezeBackward0>)\n",
      "tensor([517.1570, 624.8903, 631.5251, 573.5627], grad_fn=<SqueezeBackward0>)\n",
      "tensor([549.1655, 576.4468, 655.1602, 601.0707], grad_fn=<SqueezeBackward0>)\n",
      "tensor([620.0964, 620.1664, 591.8963, 627.7184], grad_fn=<SqueezeBackward0>)\n",
      "tensor([596.6874, 675.4989, 662.1210, 614.3227], grad_fn=<SqueezeBackward0>)\n",
      "tensor([582.3766, 610.8822, 521.1847, 693.0992], grad_fn=<SqueezeBackward0>)\n",
      "tensor([542.3479, 614.2253, 597.6708, 616.7855], grad_fn=<SqueezeBackward0>)\n",
      "tensor([636.4520, 572.9330, 621.4948, 627.7300], grad_fn=<SqueezeBackward0>)\n",
      "tensor([639.9984, 655.9572, 607.1993, 604.8746], grad_fn=<SqueezeBackward0>)\n",
      "tensor([644.6052, 641.3246, 600.6010, 590.3544], grad_fn=<SqueezeBackward0>)\n",
      "tensor([654.0557, 606.0832, 489.6696, 657.0085], grad_fn=<SqueezeBackward0>)\n",
      "tensor([602.0302, 524.6984, 600.2408, 624.1984], grad_fn=<SqueezeBackward0>)\n",
      "tensor([606.3981, 595.1926, 605.6376, 614.9146], grad_fn=<SqueezeBackward0>)\n",
      "tensor([625.3938, 612.0964, 599.6429, 631.2872], grad_fn=<SqueezeBackward0>)\n",
      "tensor([639.6721, 654.8212, 601.9446, 611.3223], grad_fn=<SqueezeBackward0>)\n",
      "tensor([686.9297, 641.9906, 629.6049, 597.4847], grad_fn=<SqueezeBackward0>)\n",
      "tensor([663.1253, 636.1682, 655.5949, 692.2789], grad_fn=<SqueezeBackward0>)\n",
      "tensor([634.5983, 676.9268, 613.8911, 638.9434], grad_fn=<SqueezeBackward0>)\n",
      "tensor([563.0602, 575.6584, 642.0629, 588.7948], grad_fn=<SqueezeBackward0>)\n",
      "tensor([612.8436, 638.5469, 623.6021, 620.5812], grad_fn=<SqueezeBackward0>)\n",
      "tensor([653.3030, 667.1231, 657.5850, 563.4472], grad_fn=<SqueezeBackward0>)\n",
      "tensor([650.5255, 641.8535, 570.6649, 618.6304], grad_fn=<SqueezeBackward0>)\n",
      "tensor([550.2946, 729.2738, 673.8088, 613.8815], grad_fn=<SqueezeBackward0>)\n",
      "tensor([552.1533, 541.1827, 621.3059, 629.3101], grad_fn=<SqueezeBackward0>)\n",
      "tensor([620.9861, 592.0492, 706.3577, 642.0023], grad_fn=<SqueezeBackward0>)\n",
      "tensor([664.5291, 604.5773, 605.4221, 674.2305], grad_fn=<SqueezeBackward0>)\n",
      "tensor([647.8823, 709.3900, 631.5767, 620.2597], grad_fn=<SqueezeBackward0>)\n",
      "tensor([531.0225, 676.2012, 671.6726, 596.0617], grad_fn=<SqueezeBackward0>)\n",
      "tensor([708.1457, 615.2440, 627.5673, 600.1014], grad_fn=<SqueezeBackward0>)\n",
      "tensor([597.0742, 683.3215, 669.2665, 672.1302], grad_fn=<SqueezeBackward0>)\n",
      "tensor([637.5323, 652.4141, 638.7622, 617.7072], grad_fn=<SqueezeBackward0>)\n",
      "tensor([623.8945, 590.6566, 661.7422, 661.7413], grad_fn=<SqueezeBackward0>)\n",
      "tensor([594.8416, 704.5635, 660.6943, 652.8246], grad_fn=<SqueezeBackward0>)\n",
      "tensor([679.9282, 590.3448, 659.6752, 622.3233], grad_fn=<SqueezeBackward0>)\n",
      "tensor([641.3181, 601.4902, 680.1672, 632.2992], grad_fn=<SqueezeBackward0>)\n",
      "tensor([634.8218, 666.9656, 601.0343, 667.9703], grad_fn=<SqueezeBackward0>)\n",
      "tensor([611.1622, 623.8103, 642.0161, 672.6632], grad_fn=<SqueezeBackward0>)\n",
      "tensor([661.0672, 672.6101, 654.8398, 633.1968], grad_fn=<SqueezeBackward0>)\n",
      "tensor([699.0442, 610.1871, 686.8940, 633.4736], grad_fn=<SqueezeBackward0>)\n",
      "tensor([706.1212, 649.3478, 672.8318, 667.1760], grad_fn=<SqueezeBackward0>)\n",
      "tensor(662.4710, grad_fn=<SqueezeBackward0>)\n",
      "Epoch 10, Loss: 1.691764633161741e+16\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "class CustomMultilinearModel(nn.Module):\n",
    "    def __init__(self, vocab_size=384, video_feature_size=2048):\n",
    "        super(CustomMultilinearModel, self).__init__()\n",
    "        self.W0 = nn.Parameter(torch.randn(1))  # Bias term\n",
    "        self.W1 = nn.Parameter(torch.randn(1))  # Scalar weight for Tcount\n",
    "        self.W2 = nn.Parameter(torch.randn(vocab_size, 1))  # 384x1 vector for Tvocab\n",
    "        self.W3 = nn.Parameter(torch.randn(video_feature_size, 1))  # 2048x1 vector for mean video feature vector\n",
    "\n",
    "    def forward(self, Tcount, Tvocab, Tvideo_mean):\n",
    "        # Tcount is scalar, Tvocab is 384x1, Tvideo_mean is 2048x1\n",
    "        Y = self.W0 + self.W1 * Tcount + torch.matmul(self.W2.T, Tvocab.T) + torch.matmul(self.W3.T, Tvideo_mean.T)\n",
    "        return Y.squeeze()  # Remove extra dimensions for scalar output\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, title_count, vocab_embeddings, video_features, view_count):\n",
    "        self.title_count = title_count\n",
    "        self.vocab_embeddings = vocab_embeddings\n",
    "        self.video_features = video_features\n",
    "        self.view_count = view_count\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.view_count)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.title_count[idx], self.vocab_embeddings[idx], self.video_features[idx], self.view_count[idx])\n",
    "    \n",
    "\n",
    "# Splitting dataset into training and testing\n",
    "def train_test_split_dataset(dataset, train_size=0.75):\n",
    "    train_len = int(len(dataset) * train_size)\n",
    "    test_len = len(dataset) - train_len\n",
    "    return random_split(dataset, lengths=[train_len, test_len])\n",
    "\n",
    "def custom_loss(outputs, targets, penalty_factor=1000):\n",
    "    \"\"\"\n",
    "    Custom loss function that penalizes negative predictions.\n",
    "\n",
    "    Parameters:\n",
    "    - outputs: model predictions\n",
    "    - targets: true values\n",
    "    - penalty_factor: factor to scale the penalty for negative predictions\n",
    "\n",
    "    Returns:\n",
    "    - loss: computed loss with penalty for negative predictions\n",
    "    \"\"\"\n",
    "    mse_loss = nn.MSELoss()(outputs, targets)\n",
    "    \n",
    "    # Calculate penalty for negative predictions\n",
    "    negative_penalty = (outputs < 0).float() * penalty_factor * torch.abs(outputs)\n",
    "    negative_penalty = negative_penalty.mean()\n",
    "\n",
    "    # Total loss is the sum of MSE loss and negative penalty\n",
    "    loss = mse_loss + negative_penalty\n",
    "    return loss\n",
    "\n",
    "\n",
    "# load data\n",
    "title_count = length_title_view_count['length_title']\n",
    "vocab_embeddings = vocab_embeds\n",
    "video_features = np.array(list(frames_features.values()))\n",
    "view_count = length_title_view_count['view count']\n",
    "\n",
    "\n",
    "\n",
    "# Initialize dataset and split\n",
    "dataset = VideoDataset(title_count, vocab_embeddings, video_features, view_count)\n",
    "train_dataset, test_dataset = train_test_split_dataset(dataset)\n",
    "\n",
    "# DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = CustomMultilinearModel(vocab_size=384, video_feature_size=2048)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()    \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Example scheduler\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        title_count, vocab_embed, video_mean, view_counts = data\n",
    "        # Tcount = torch.tensor([[len(v)] for v in vocab_embed])  # Example way to compute Tcount, adjust as necessary\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(title_count, vocab_embed.float(), video_mean.float())\n",
    "        print(outputs)\n",
    "        loss = custom_loss(outputs, view_counts.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 475854067507850.2, Mean Percentage Error: 99.99771045503162%\n",
      "Epoch 2, Loss: 475245997186941.94, Mean Percentage Error: 99.93599277072482%\n",
      "Epoch 3, Loss: 480927147302001.75, Mean Percentage Error: 99.68545471675812%\n",
      "Epoch 4, Loss: 486714111617966.75, Mean Percentage Error: 99.02152845594618%\n",
      "Epoch 5, Loss: 475969761991013.56, Mean Percentage Error: 97.67804209391277%\n",
      "Epoch 6, Loss: 486023649154909.44, Mean Percentage Error: 95.51323784722223%\n",
      "Epoch 7, Loss: 477556716189403.44, Mean Percentage Error: 92.2081788078187%\n",
      "Epoch 8, Loss: 474700325792946.8, Mean Percentage Error: 89.15783079843672%\n",
      "Epoch 9, Loss: 459175161333272.4, Mean Percentage Error: 87.35084497360955%\n",
      "Epoch 10, Loss: 464688377008713.1, Mean Percentage Error: 87.92383345346602%\n",
      "Epoch 11, Loss: 445985085814231.4, Mean Percentage Error: 87.50524602617536%\n",
      "Epoch 12, Loss: 453222516150597.06, Mean Percentage Error: 89.09295024569073%\n",
      "Epoch 13, Loss: 444489251805021.44, Mean Percentage Error: 91.17991208273267%\n",
      "Epoch 14, Loss: 424704650997174.9, Mean Percentage Error: 94.20618511381603%\n",
      "Epoch 15, Loss: 414612599927759.25, Mean Percentage Error: 98.4063618372357%\n",
      "Epoch 16, Loss: 416003003048846.25, Mean Percentage Error: 103.64792100210039%\n",
      "Epoch 17, Loss: 398344364948463.75, Mean Percentage Error: 109.55281103224982%\n",
      "Epoch 18, Loss: 396022357742413.2, Mean Percentage Error: 115.94708581954714%\n",
      "Epoch 19, Loss: 385740427534986.2, Mean Percentage Error: 122.56990084572443%\n",
      "Epoch 20, Loss: 381574077239621.06, Mean Percentage Error: 133.42260717967199%\n",
      "Epoch 21, Loss: 374968223934626.56, Mean Percentage Error: 137.3467758420914%\n",
      "Epoch 22, Loss: 379257712304518.1, Mean Percentage Error: 144.56723912556967%\n",
      "Epoch 23, Loss: 371017546881381.56, Mean Percentage Error: 150.03100707039002%\n",
      "Epoch 24, Loss: 370209033635092.3, Mean Percentage Error: 157.16598595513238%\n",
      "Epoch 25, Loss: 364364993862769.75, Mean Percentage Error: 166.51979104299394%\n",
      "Epoch 26, Loss: 366244045383582.5, Mean Percentage Error: 172.3911358969552%\n",
      "Epoch 27, Loss: 360290137182793.1, Mean Percentage Error: 178.60916779533264%\n",
      "Epoch 28, Loss: 359013668002409.6, Mean Percentage Error: 185.0800553579179%\n",
      "Epoch 29, Loss: 354376668131002.94, Mean Percentage Error: 188.15887632824126%\n",
      "Epoch 30, Loss: 350811084242163.8, Mean Percentage Error: 192.83771216680134%\n",
      "Epoch 31, Loss: 353925638310700.7, Mean Percentage Error: 195.63331785656158%\n",
      "Epoch 32, Loss: 356626990387525.06, Mean Percentage Error: 200.14173986041357%\n",
      "Epoch 33, Loss: 357034549309375.0, Mean Percentage Error: 203.77762261648027%\n",
      "Epoch 34, Loss: 353932162317555.8, Mean Percentage Error: 204.97841308230446%\n",
      "Epoch 35, Loss: 349284874084742.1, Mean Percentage Error: 210.53792729453434%\n",
      "Epoch 36, Loss: 348845979118250.7, Mean Percentage Error: 212.53809529259092%\n",
      "Epoch 37, Loss: 349683860714707.3, Mean Percentage Error: 217.9853751470172%\n",
      "Epoch 38, Loss: 350543101704419.56, Mean Percentage Error: 246.3511696467324%\n",
      "Epoch 39, Loss: 347947018202810.94, Mean Percentage Error: 226.53566869099936%\n",
      "Epoch 40, Loss: 347965366618404.56, Mean Percentage Error: 230.14630020989313%\n",
      "Epoch 41, Loss: 347349446923865.4, Mean Percentage Error: 236.4192151266431%\n",
      "Epoch 42, Loss: 347653583829479.6, Mean Percentage Error: 240.35847418648856%\n",
      "Epoch 43, Loss: 346477975343689.1, Mean Percentage Error: 248.56392018757168%\n",
      "Epoch 44, Loss: 345799235760583.1, Mean Percentage Error: 249.11711965288436%\n",
      "Epoch 45, Loss: 346107232823978.7, Mean Percentage Error: 257.37500145321803%\n",
      "Epoch 46, Loss: 350591683728465.25, Mean Percentage Error: 255.51072462778242%\n",
      "Epoch 47, Loss: 350494511691223.4, Mean Percentage Error: 257.77542162698415%\n",
      "Epoch 48, Loss: 344666954501688.9, Mean Percentage Error: 257.39359337942943%\n",
      "Epoch 49, Loss: 344053953110666.2, Mean Percentage Error: 260.0913122873458%\n",
      "Epoch 50, Loss: 347197695806772.8, Mean Percentage Error: 271.75913644215416%\n",
      "Epoch 51, Loss: 345611269957534.5, Mean Percentage Error: 259.2387931460426%\n",
      "Epoch 52, Loss: 348462668865926.1, Mean Percentage Error: 262.42480023701984%\n",
      "Epoch 53, Loss: 354348720085349.56, Mean Percentage Error: 262.2395725552998%\n",
      "Epoch 54, Loss: 345570289876471.9, Mean Percentage Error: 265.4552948361351%\n",
      "Epoch 55, Loss: 346414812387685.56, Mean Percentage Error: 264.58886894347177%\n",
      "Epoch 56, Loss: 344533625566679.4, Mean Percentage Error: 266.16616797068764%\n",
      "Epoch 57, Loss: 349114530150627.56, Mean Percentage Error: 267.1590472630092%\n",
      "Epoch 58, Loss: 346726324677290.7, Mean Percentage Error: 271.0046996464805%\n",
      "Epoch 59, Loss: 351053576862703.75, Mean Percentage Error: 267.02715428670246%\n",
      "Epoch 60, Loss: 356318933205772.2, Mean Percentage Error: 269.1116062345959%\n",
      "Epoch 61, Loss: 352982732873337.9, Mean Percentage Error: 268.94183104378834%\n",
      "Epoch 62, Loss: 345745026644975.75, Mean Percentage Error: 270.46134001111227%\n",
      "Epoch 63, Loss: 342855734064079.25, Mean Percentage Error: 266.8799456187657%\n",
      "Epoch 64, Loss: 342567878780830.5, Mean Percentage Error: 266.56579259085277%\n",
      "Epoch 65, Loss: 352620088422855.1, Mean Percentage Error: 267.1489465804327%\n",
      "Epoch 66, Loss: 350120258472488.6, Mean Percentage Error: 269.5642132229275%\n",
      "Epoch 67, Loss: 345784308565528.4, Mean Percentage Error: 268.57948206341456%\n",
      "Epoch 68, Loss: 345572662121553.25, Mean Percentage Error: 276.1179663037497%\n",
      "Epoch 69, Loss: 346579179904633.9, Mean Percentage Error: 270.77582880050414%\n",
      "Epoch 70, Loss: 345128629798424.4, Mean Percentage Error: 269.176025148422%\n",
      "Epoch 71, Loss: 352619280986047.0, Mean Percentage Error: 266.1204193962945%\n",
      "Epoch 72, Loss: 344422368790300.44, Mean Percentage Error: 267.9243630303277%\n",
      "Epoch 73, Loss: 345939925432807.6, Mean Percentage Error: 266.41345305669876%\n",
      "Epoch 74, Loss: 344565903865043.3, Mean Percentage Error: 269.52748680114746%\n",
      "Epoch 75, Loss: 357183959738530.56, Mean Percentage Error: 267.0770727490622%\n",
      "Epoch 76, Loss: 344942003243300.56, Mean Percentage Error: 269.1676165868366%\n",
      "Epoch 77, Loss: 347383849803645.94, Mean Percentage Error: 266.6422372848269%\n",
      "Epoch 78, Loss: 347258304697945.4, Mean Percentage Error: 287.050539289202%\n",
      "Epoch 79, Loss: 352756960146643.3, Mean Percentage Error: 267.721131279355%\n",
      "Epoch 80, Loss: 346078219291956.8, Mean Percentage Error: 270.45287680247475%\n",
      "Epoch 81, Loss: 345381128497054.5, Mean Percentage Error: 268.9875136784145%\n",
      "Epoch 82, Loss: 345321710388760.4, Mean Percentage Error: 268.51500290159197%\n",
      "Epoch 83, Loss: 344962057475673.4, Mean Percentage Error: 265.82298763214595%\n",
      "Epoch 84, Loss: 346226707040808.6, Mean Percentage Error: 271.01161327059305%\n",
      "Epoch 85, Loss: 348024147458795.7, Mean Percentage Error: 267.9622547210209%\n",
      "Epoch 86, Loss: 342107534010530.56, Mean Percentage Error: 267.3069101212517%\n",
      "Epoch 87, Loss: 358471322791350.9, Mean Percentage Error: 268.18370249914744%\n",
      "Epoch 88, Loss: 345917027395746.56, Mean Percentage Error: 272.88665686713324%\n",
      "Epoch 89, Loss: 345694942727216.75, Mean Percentage Error: 273.91655337621296%\n",
      "Epoch 90, Loss: 347771081730210.56, Mean Percentage Error: 266.8238104260157%\n",
      "Epoch 91, Loss: 344016942838475.2, Mean Percentage Error: 268.2251080104283%\n",
      "Epoch 92, Loss: 344831862950700.7, Mean Percentage Error: 268.660644289047%\n",
      "Epoch 93, Loss: 343890103224092.44, Mean Percentage Error: 266.8915159740145%\n",
      "Epoch 94, Loss: 345711848967996.94, Mean Percentage Error: 287.02650403219553%\n",
      "Epoch 95, Loss: 346946258200478.5, Mean Percentage Error: 266.0900511363196%\n",
      "Epoch 96, Loss: 344264560033011.8, Mean Percentage Error: 275.28350000532845%\n",
      "Epoch 97, Loss: 349257540071879.1, Mean Percentage Error: 266.3014306567964%\n",
      "Epoch 98, Loss: 344231667368976.25, Mean Percentage Error: 266.6980641077435%\n",
      "Epoch 99, Loss: 348731322625462.9, Mean Percentage Error: 267.0581330798921%\n",
      "Epoch 100, Loss: 345401837174003.8, Mean Percentage Error: 268.01004367404516%\n",
      "Epoch 101, Loss: 344108279866514.3, Mean Percentage Error: 266.6225685543484%\n",
      "Epoch 102, Loss: 344080504319935.0, Mean Percentage Error: 267.5304091014559%\n",
      "Epoch 103, Loss: 344643274260219.94, Mean Percentage Error: 267.4228266155909%\n",
      "Epoch 104, Loss: 350629551769112.4, Mean Percentage Error: 269.3628646608383%\n",
      "Epoch 105, Loss: 350454584413752.9, Mean Percentage Error: 268.6334094698467%\n",
      "Epoch 106, Loss: 344549921303210.7, Mean Percentage Error: 272.0480068751744%\n",
      "Epoch 107, Loss: 341102228847339.7, Mean Percentage Error: 266.445036237202%\n",
      "Epoch 108, Loss: 351736085727004.44, Mean Percentage Error: 267.52905097840323%\n",
      "Epoch 109, Loss: 343007668665327.75, Mean Percentage Error: 269.8552276369125%\n",
      "Epoch 110, Loss: 349873000523418.44, Mean Percentage Error: 267.32501438685824%\n",
      "Epoch 111, Loss: 344167250449229.2, Mean Percentage Error: 268.29873884291874%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [217]\u001b[0m, in \u001b[0;36m<cell line: 115>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m loss \u001b[38;5;241m=\u001b[39m custom_loss(outputs, view_counts) \u001b[38;5;241m+\u001b[39m l1_lambda \u001b[38;5;241m*\u001b[39m l1_norm\n\u001b[0;32m    137\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 138\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    141\u001b[0m total_percentage_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m calculate_percentage_error(outputs, view_counts)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     68\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:344\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    341\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    345\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "class CustomNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, vocab_size=384, video_feature_size=2048, hidden_size=512, dropout_rate=0.01):\n",
    "        super(CustomNeuralNetworkModel, self).__init__()\n",
    "        # Define the first layer weights\n",
    "        self.fc1_vocab = nn.Linear(vocab_size, hidden_size)\n",
    "        self.fc1_video = nn.Linear(video_feature_size, hidden_size)\n",
    "        self.fc1_title = nn.Linear(1, hidden_size)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Define the second layer (hidden layer) weights\n",
    "        self.fc2 = nn.Linear(hidden_size * 3, hidden_size)  # Combining all features into a single hidden layer\n",
    "\n",
    "        # Output layer\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Non-linear activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, Tcount, Tvocab, Tvideo_mean):\n",
    "        # Ensure all inputs are of type torch.float32\n",
    "        Tcount = Tcount.float()\n",
    "        Tvocab = Tvocab.float()\n",
    "        Tvideo_mean = Tvideo_mean.float()\n",
    "\n",
    "        # Process each input through its respective first layer and apply ReLU activation\n",
    "        Tcount = self.relu(self.fc1_title(Tcount))\n",
    "        Tvocab = self.relu(self.fc1_vocab(Tvocab))\n",
    "        Tvideo_mean = self.relu(self.fc1_video(Tvideo_mean))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        combined_features = torch.cat((Tcount, Tvocab, Tvideo_mean), dim=1)\n",
    "        \n",
    "        # Pass through additional hidden layers with ReLU activation and dropout\n",
    "        hidden_output = self.relu(self.fc2(combined_features))\n",
    "        hidden_output = self.dropout(hidden_output)\n",
    "        \n",
    "        # Output layer\n",
    "        Y = self.fc3(hidden_output)\n",
    "        return Y.squeeze()  # Remove extra dimensions for scalar output\n",
    "\n",
    "def custom_loss(outputs, targets, error_threshold=15.0, reward_factor=1000000):\n",
    "    \"\"\"\n",
    "    Custom loss function that penalizes:\n",
    "    1. Negative predictions.\n",
    "    2. Predictions with percentage error greater than a specified threshold (e.g., 20%).\n",
    "\n",
    "    Parameters:\n",
    "    - outputs: model predictions.\n",
    "    - targets: true values.\n",
    "    - penalty_factor: factor to scale the penalty for negative predictions and high percentage errors.\n",
    "    - error_threshold: percentage error threshold beyond which to apply penalties.\n",
    "\n",
    "    Returns:\n",
    "    - loss: computed loss with penalties for negative predictions and high percentage errors.\n",
    "    \"\"\"\n",
    "    mse_loss = nn.MSELoss()(outputs, targets)\n",
    "    \n",
    "    # Calculate penalty for negative predictions\n",
    "    negative_penalty = (outputs < 0).float() * 50000000 * torch.abs(outputs)\n",
    "    negative_penalty = negative_penalty.mean()\n",
    "\n",
    "    percentage_error = torch.abs((outputs - targets) / targets) * 100\n",
    "    error_penalty = (percentage_error > error_threshold).float() * 5000000 * torch.abs(outputs - targets)\n",
    "    error_penalty = error_penalty.mean()\n",
    "\n",
    "    # Reward for predictions within the error threshold\n",
    "    reward = (percentage_error <= error_threshold).float() * reward_factor * torch.abs(outputs - targets)\n",
    "    reward = reward.mean()\n",
    "\n",
    "    loss = mse_loss + negative_penalty + error_penalty - reward\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calculate_percentage_error(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculate the percentage error between predicted and actual values.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicted: Predicted values by the model.\n",
    "    - actual: Actual values.\n",
    "    \n",
    "    Returns:\n",
    "    - percentage_error: The mean percentage error.\n",
    "    \"\"\"\n",
    "    percentage_error = torch.abs((predicted - actual) / actual) * 100\n",
    "    return percentage_error.mean()\n",
    "\n",
    "def standardize(tensor, mean, std):\n",
    "    return (tensor - mean) / (std + 1e-3)\n",
    "\n",
    "# Assuming you have a DataLoader for your training data: train_loader\n",
    "# First, calculate the mean and std for vocab_embed and video_mean features from the training data\n",
    "\n",
    "# Placeholder for mean and std calculation\n",
    "vocab_embed_mean, vocab_embed_std = torch.tensor(0.0), torch.tensor(1.0)\n",
    "video_mean_mean, video_mean_std = torch.tensor(0.0), torch.tensor(1.0)\n",
    "\n",
    "# Initialize model with a specified hidden size\n",
    "model = CustomNeuralNetworkModel(vocab_size=384, video_feature_size=2048, hidden_size=512)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00035, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    total_percentage_error = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        title_count, vocab_embed, video_mean, view_counts = data\n",
    "        title_count = title_count.unsqueeze(1).float()\n",
    "        \n",
    "        # Standardize features\n",
    "        vocab_embed = standardize(vocab_embed.float(), vocab_embed_mean, vocab_embed_std)\n",
    "        video_mean = standardize(video_mean.float(), video_mean_mean, video_mean_std)\n",
    "        \n",
    "        view_counts = view_counts.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(title_count, vocab_embed, video_mean)\n",
    "\n",
    "        l1_lambda = 0.0001\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss = custom_loss(outputs, view_counts) + l1_lambda * l1_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_percentage_error += calculate_percentage_error(outputs, view_counts).item()\n",
    "        count += 1\n",
    "\n",
    "    mean_percentage_error = total_percentage_error / count\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Mean Percentage Error: {mean_percentage_error}%')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Input, concatenate, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_video_features(video_frames_folder):\n",
    "    \"\"\"\n",
    "    Extracts features from video frames using ResNet50.\n",
    "    \"\"\"\n",
    "    cnn_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    features_list = []\n",
    "    for frame in sorted(os.listdir(video_frames_folder)):\n",
    "        img_path = os.path.join(video_frames_folder, frame)\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "        features = cnn_model.predict(expanded_img_array)\n",
    "        pooled_features = GlobalAveragePooling2D()(features)\n",
    "        features_list.append(pooled_features)\n",
    "    return np.array(features_list)\n",
    "\n",
    "def preprocess_metadata(metadata_df):\n",
    "    \"\"\"\n",
    "    Preprocesses metadata using standard scaling.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_metadata = scaler.fit_transform(metadata_df)\n",
    "    return scaled_metadata\n",
    "\n",
    "def create_hybrid_model(metadata_shape, video_feature_shape):\n",
    "    \"\"\"\n",
    "    Creates a hybrid model combining NN for metadata and CNN-LSTM for video content.\n",
    "    \"\"\"\n",
    "    # Metadata input branch\n",
    "    metadata_input = Input(shape=(metadata_shape,), name='metadata_input')\n",
    "    metadata_branch = Dense(128, activation='relu')(metadata_input)\n",
    "    \n",
    "    # Video content input branch\n",
    "    video_input = Input(shape=(None, video_feature_shape), name='video_input')\n",
    "    video_branch = LSTM(256, return_sequences=True)(video_input)\n",
    "    video_branch = LSTM(128)(video_branch)\n",
    "    \n",
    "    # Merge branches\n",
    "    merged = concatenate([metadata_branch, video_branch])\n",
    "    merged = Dense(64, activation='relu')(merged)\n",
    "    output = Dense(1, activation='linear')(merged)\n",
    "    \n",
    "    model = Model(inputs=[metadata_input, video_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Assume 'metadata.csv' contains video metadata and 'videos/' contains video frame folders\n",
    "metadata_df = pd.read_csv('metadata.csv')\n",
    "video_features = []  # Placeholder for extracted video features\n",
    "for video_folder in sorted(os.listdir('videos/')):\n",
    "    folder_path = os.path.join('videos/', video_folder)\n",
    "    video_features.append(extract_video_features(folder_path))\n",
    "\n",
    "# Preprocess metadata\n",
    "metadata = preprocess_metadata(metadata_df)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_meta, X_test_meta, X_train_video, X_test_video, y_train, y_test = train_test_split(\n",
    "    metadata, video_features, scores, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = create_hybrid_model(metadata.shape[1], video_features.shape[2])\n",
    "\n",
    "# Assuming 'scores' is a numpy array containing the target engagement scores\n",
    "model.fit([X_train_meta, X_train_video], y_train, validation_split=0.2, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate([X_test_meta, X_test_video], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'img_to_array' from 'keras.preprocessing.image' (c:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_to_array, load_img\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the pre-trained ResNet50 model for feature extraction\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'img_to_array' from 'keras.preprocessing.image' (c:\\Users\\howel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the pre-trained ResNet50 model for feature extraction\n",
    "def load_cnn_model():\n",
    "    return keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Function to extract features from a single image\n",
    "def extract_features(img_path, cnn_model):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = keras.applications.resnet50.preprocess_input(expanded_img_array)\n",
    "    features = cnn_model.predict(preprocessed_img)\n",
    "    return features\n",
    "\n",
    "# Function to process a video and calculate mean feature vector\n",
    "def process_video(video_frames_folder, cnn_model):\n",
    "    frame_features = []\n",
    "    for frame in sorted(os.listdir(video_frames_folder)):\n",
    "        frame_path = os.path.join(video_frames_folder, frame)\n",
    "        features = extract_features(frame_path, cnn_model)\n",
    "        frame_features.append(features)\n",
    "    if frame_features:\n",
    "        mean_feature_vector = np.mean(np.array(frame_features).squeeze(), axis=0)\n",
    "        return mean_feature_vector\n",
    "    return None\n",
    "\n",
    "# Load the saved LSTM model\n",
    "def load_lstm_model(model_path='model/most_replayed_model.keras'):\n",
    "    return keras.models.load_model(model_path)\n",
    "\n",
    "# Main script to predict intensity scores for a video\n",
    "def predict_intensity_scores(video_frames_folder, cnn_model, lstm_model):\n",
    "    # Process the video to get the mean feature vector\n",
    "    mean_feature_vector = process_video(video_frames_folder, cnn_model)\n",
    "    if mean_feature_vector is not None:\n",
    "        # Predict the intensity score using the LSTM model\n",
    "        mean_feature_vector = np.expand_dims(mean_feature_vector, axis=0)  # Add batch dimension\n",
    "        predicted_intensity_score = lstm_model.predict(mean_feature_vector)\n",
    "        return predicted_intensity_score\n",
    "    return None\n",
    "\n",
    "# Assuming you have true intensity scores for evaluation\n",
    "def evaluate_model(true_intensity_scores, predicted_intensity_scores):\n",
    "    mse = mean_squared_error(true_intensity_scores, predicted_intensity_scores)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Example usage\n",
    "video_frames_folder = \"videos/_7VXXHn-AaY\"  # Update this path\n",
    "true_intensity_scores = np.array([0.5])  # Example true intensity score\n",
    "\n",
    "cnn_model = load_cnn_model()\n",
    "lstm_model = load_lstm_model()\n",
    "predicted_intensity_scores = predict_intensity_scores(video_frames_folder, cnn_model, lstm_model)\n",
    "\n",
    "if predicted_intensity_scores is not None:\n",
    "    print(f\"Predicted Intensity Score: {predicted_intensity_scores}\")\n",
    "    evaluate_model(true_intensity_scores, predicted_intensity_scores)\n",
    "else:\n",
    "    print(\"Could not process video.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
